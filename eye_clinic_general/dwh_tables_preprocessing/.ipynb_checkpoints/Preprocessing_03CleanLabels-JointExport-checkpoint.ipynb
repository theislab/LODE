{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Clean Labels\n",
    "Clean each label file individually\n",
    "- Reads dwh tables from `/storage/groups/ml01/datasets/raw/2018_LMUAugenklinik_niklas.koehler/dwh_tables`\n",
    "- Writes cleaned dwh tables to `/storage/groups/ml01/datasets/projects/20181610_eyeclinic_niklas.koehler/dwh_tables_cleaned`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from ipywidgets import interact, fixed\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "from pydicom import read_file\n",
    "from tqdm import tqdm\n",
    "import imageio\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../DeepRT/thickness_map_calculation')\n",
    "import dicom_table as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DIR = \"/storage/groups/ml01/datasets/raw/2018_LMUAugenklinik_niklas.koehler\"\n",
    "\n",
    "data_dir = os.path.join(RAW_DIR, 'joint_export/dwh_tables')\n",
    "# data_dir = '../../raw_data/dwh_tables'  # for local data\n",
    "clean_data_dir = '/storage/groups/ml01/datasets/projects/20181610_eyeclinic_niklas.koehler/joint_export/dwh_tables_cleaned'\n",
    "# clean_data_dir = '../../raw_data/dwh_tables_cleaned'  # for local data\n",
    "longitudinal_dir = os.path.join(RAW_DIR, \"joint_export/longitudinal_tables\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diagnosis_check_1 = pd.read_csv(os.path.join(longitudinal_dir, 'longitudinal_records_with_date_CHECKED.csv'), \n",
    "                                 index_col=0)\n",
    "\n",
    "diagnosis_check_2 = pd.read_csv(os.path.join(longitudinal_dir, 'check_naive_patients_CORRECTED.csv'), \n",
    "                                 index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pseudo_id</th>\n",
       "      <th>first_injection_date</th>\n",
       "      <th>ICPML</th>\n",
       "      <th>LOK</th>\n",
       "      <th>Naive</th>\n",
       "      <th>Note</th>\n",
       "      <th>Cat</th>\n",
       "      <th>Cat-Date</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>380441</td>\n",
       "      <td>2/12/2020</td>\n",
       "      <td>5-156.9</td>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>379576</td>\n",
       "      <td>1/9/2020</td>\n",
       "      <td>5-156.9</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>Ozurdex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>378420</td>\n",
       "      <td>3/31/2020</td>\n",
       "      <td>5-156.9</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>Enophtalmitis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>380200</td>\n",
       "      <td>7/9/2018</td>\n",
       "      <td>5-156.9</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>DME</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>382606</td>\n",
       "      <td>10/8/2020</td>\n",
       "      <td>5-156.9</td>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pseudo_id first_injection_date    ICPML LOK  Naive           Note  Cat  \\\n",
       "0     380441            2/12/2020  5-156.9   R      1            NaN  2.0   \n",
       "1     379576             1/9/2020  5-156.9   L      0        Ozurdex  NaN   \n",
       "2     378420            3/31/2020  5-156.9   L      0  Enophtalmitis  NaN   \n",
       "3     380200             7/9/2018  5-156.9   L      0            DME  NaN   \n",
       "4     382606            10/8/2020  5-156.9   R      1            NaN  1.0   \n",
       "\n",
       "  Cat-Date Unnamed: 9  \n",
       "0      NaN        NaN  \n",
       "1      NaN        NaN  \n",
       "2      NaN        NaN  \n",
       "3      NaN        NaN  \n",
       "4      NaN        NaN  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagnosis_check_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean visus labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_logMAR(va):\n",
    "    # converts decimal va values to logMAR scale\n",
    "    try:\n",
    "        va = float(va)\n",
    "        if va == 0:\n",
    "            return np.inf\n",
    "        else:\n",
    "            return np.log10(1/va)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "def get_visual_acuity(group):\n",
    "    # parses items in ordered group. If first value cannot be parsed, moves on to next value\n",
    "    for i, raw in enumerate(list(group.visual_acuity_raw)):\n",
    "        va = parse_visual_acuity(raw)\n",
    "        if va is not None:\n",
    "            res = list(group.iloc[i])\n",
    "            res.append(va)\n",
    "            return res\n",
    "    return None\n",
    "\n",
    "def parse_visual_acuity(raw):\n",
    "    if pd.isna(raw):\n",
    "        return None\n",
    "    \n",
    "    # match range of two comma/dot separated values\n",
    "    m = re.match(r'.*(\\d+)[,\\.](\\d+)[ -]+(\\d+)[,\\.](\\d+).*$', raw)\n",
    "    if m:\n",
    "        return np.mean([float('{}.{}'.format(m.group(1), m.group(2))), \n",
    "                       float('{}.{}'.format(m.group(3), m.group(4)))])\n",
    "    \n",
    "    # match comma/dot separated value, allowing comma, space, \"sc\" as first character\n",
    "    m = re.match(r'[ ,\\.a-zA-Z]*([\\do]+)[\\., ]+(\\d+).*$', raw)\n",
    "    if m:\n",
    "        return float('{}.{}'.format(m.group(1).replace('o', '0'), m.group(2)))\n",
    "    \n",
    "    # match two integer values separated with /, allowing space, \"sc, HT\" as first character\n",
    "    m = re.match(r'[ a-zA-Z:]*(\\d+)[ /]+(\\d+)[a-zA-Z \\.]*$', raw)\n",
    "    if m:\n",
    "        return int(m.group(1))/float(m.group(2))\n",
    "        \n",
    "    # match HBW\n",
    "    if re.match(r'.*[hH]\\.*[bB]\\.*[wW]*\\.*', raw):\n",
    "        return 'HBW'\n",
    "    # match FZ\n",
    "    elif re.match(r'[fF]\\.*[zZ]\\.*', raw):\n",
    "        return 'FZ'\n",
    "    # match Lilo\n",
    "    elif re.match(r'li(cht){0,1}(lo(kal){0,1}){0,1}', raw, flags=re.IGNORECASE):\n",
    "        return 'LILO'\n",
    "    # match Nulla LUX\n",
    "    elif re.match(r'(n[ulla]*|kein)\\.* *l([ux\\.]*|[icht]*)', raw, flags=re.IGNORECASE):        \n",
    "        return 'NL'\n",
    "    # match FIX\n",
    "    elif re.match(r'fix.*', raw, flags=re.IGNORECASE):\n",
    "        return 'FIX'\n",
    "    # match LUX\n",
    "    elif re.match(r'.*lux.*', raw, flags=re.IGNORECASE):  \n",
    "        return 'LUX'\n",
    "    \n",
    "    else:\n",
    "        return \"other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icb/olle.holmberg/anaconda3/envs/tf2_super/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (5,8) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/home/icb/olle.holmberg/anaconda3/envs/tf2_super/lib/python3.6/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with 1212908 measurements\n",
      "Dropped 2 exact duplicates\n",
      "Resolving 483504 duplicate measurements per time point\n"
     ]
    }
   ],
   "source": [
    "visus_labels = pd.read_csv(os.path.join(data_dir, 'visus_labels.csv'), index_col=0)\n",
    "print('Starting with {} measurements'.format(len(visus_labels)))\n",
    "\n",
    "# rename columns\n",
    "visus_labels.rename(columns={'AUGE': 'laterality_raw', 'MEASUREMENT_DATE':'study_date', 'PATNR':'patient_id',\n",
    "                            'visual_acuity_VISUS': 'visual_acuity_raw', 'ORIGIN_TYPE': 'visual_acuity_origin'}, \n",
    "                    inplace=True)\n",
    "\n",
    "# format columns \n",
    "visus_labels.study_date = pd.to_datetime(visus_labels.study_date)\n",
    "\n",
    "# imputer origin value, ok?\n",
    "visus_labels.visual_acuity_origin.fillna(\"OR\", inplace=True)\n",
    "\n",
    "visus_labels.visual_acuity_origin = pd.Categorical(visus_labels.visual_acuity_origin,\n",
    "                                                   ['SR', 'OR', 'CC', 'STP', 'SC'])\n",
    "\n",
    "# remove rows with missing study dates\n",
    "visus_labels = visus_labels[~ visus_labels.study_date.isna()]\n",
    "\n",
    "# duplicate entries for laterality=='B'\n",
    "visus_labels['laterality'] = visus_labels['laterality_raw']\n",
    "visus_labels.loc[visus_labels['laterality_raw'] == 'B', 'laterality'] = 'L'\n",
    "visus_R = visus_labels.loc[visus_labels['laterality_raw'] == 'B'].copy().assign(laterality='R')\n",
    "visus_labels = visus_labels.append(visus_R, ignore_index=True)\n",
    "\n",
    "# get rid of exact duplicates\n",
    "num_raw = visus_labels.shape[0]\n",
    "visus_labels = visus_labels.drop_duplicates(keep='first')\n",
    "num_raw_nodup = visus_labels.shape[0]\n",
    "print('Dropped {} exact duplicates'.format(num_raw-num_raw_nodup))\n",
    "\n",
    "# count duplicate measurements per time point\n",
    "num_dups = sum(visus_labels.duplicated(['study_date', 'patient_id', 'laterality']))\n",
    "print('Resolving {} duplicate measurements per time point'.format(num_dups))\n",
    "\n",
    "# group by time point measurements\n",
    "groups = visus_labels.groupby(['patient_id', 'laterality', 'study_date'])\n",
    "keys = groups.groups.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(820689, 820689, 820005)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(visus_labels.CALCULATED_VALUE.isna()), sum(visus_labels.LOGMAR_VALUE.isna()), sum(visus_labels.MEASUREMENT_VALUE.isna()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge new VA MEASUREMENT_VALUE in visual acuity RAW COLUMN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "visus_labels.visual_acuity_raw.fillna(visus_labels.MEASUREMENT_VALUE, inplace=True)\n",
    "visus_labels.visual_acuity_raw.fillna(visus_labels.CALCULATED_VALUE, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save away all measurements to use for imputation later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_measurements = visus_labels[['patient_id', 'laterality', 'study_date', \n",
    "              \"CALCULATED_VALUE\", \"LOGMAR_VALUE\", \"MEASUREMENT_VALUE\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "visus_labels.drop(columns=[\"CALCULATED_VALUE\", \"LOGMAR_VALUE\", \"MEASUREMENT_VALUE\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse all visual acuity values into rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/730081 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before visual acuity parsing: 730081 unique time/patient/laterality measurements\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 730081/730081 [30:56<00:00, 393.36it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\n# Below code parallelizes the VA parsing accross 10 processors. Despite of copy handling speed is\\n# rouhly doubled compared to a simple for loop.\\n\\nimport time\\nfrom multiprocess import Pool\\nimport multiprocessing\\n\\ndef loop_f(key):\\n    grp = groups.get_group(key).sort_values('visual_acuity_origin')\\n    res = get_visual_acuity(grp)\\n    if res is not None:\\n        return res\\n    \\nmax_pool = 8\\n\\nstart = time.time()\\nwith Pool(max_pool) as p:\\n    rows = list(\\n        tqdm(\\n            p.imap(loop_f,\\n                   list(keys)[0:1000]),\\n            total=len(keys)\\n        )\\n    ) \\n\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Before visual acuity parsing: {} unique time/patient/laterality measurements'.format(len(keys)))\n",
    "\n",
    "rows = []\n",
    "for key in tqdm(keys):\n",
    "    # sort values to ensure that correct VA value is taken \n",
    "    grp = groups.get_group(key).sort_values('visual_acuity_origin')\n",
    "    res = get_visual_acuity(grp)\n",
    "    if res is not None:\n",
    "        rows.append(res)\n",
    "        \n",
    "'''\n",
    "\n",
    "# Below code parallelizes the VA parsing accross 10 processors. Despite of copy handling speed is\n",
    "# rouhly doubled compared to a simple for loop.\n",
    "\n",
    "import time\n",
    "from multiprocess import Pool\n",
    "import multiprocessing\n",
    "\n",
    "def loop_f(key):\n",
    "    grp = groups.get_group(key).sort_values('visual_acuity_origin')\n",
    "    res = get_visual_acuity(grp)\n",
    "    if res is not None:\n",
    "        return res\n",
    "    \n",
    "max_pool = 8\n",
    "\n",
    "start = time.time()\n",
    "with Pool(max_pool) as p:\n",
    "    rows = list(\n",
    "        tqdm(\n",
    "            p.imap(loop_f,\n",
    "                   list(keys)[0:1000]),\n",
    "            total=len(keys)\n",
    "        )\n",
    "    ) \n",
    "'''"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cleaned measurements 730080\n"
     ]
    }
   ],
   "source": [
    "visus_labels_clean = pd.DataFrame.from_records(rows, columns=['laterality_raw', 'study_date', 'visual_acuity_origin',\n",
    "                                                              'patient_id', 'visual_acuity_raw', 'laterality', \n",
    "                                                              'visual_acuity'])\n",
    "\n",
    "print('Number of cleaned measurements {}'.format(visus_labels_clean.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>laterality_raw</th>\n",
       "      <th>study_date</th>\n",
       "      <th>visual_acuity_origin</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>visual_acuity_raw</th>\n",
       "      <th>laterality</th>\n",
       "      <th>visual_acuity</th>\n",
       "      <th>logMAR_raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32151</th>\n",
       "      <td>R</td>\n",
       "      <td>2012-08-17</td>\n",
       "      <td>SC</td>\n",
       "      <td>15696</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32152</th>\n",
       "      <td>R</td>\n",
       "      <td>2012-10-31</td>\n",
       "      <td>SC</td>\n",
       "      <td>15696</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32153</th>\n",
       "      <td>R</td>\n",
       "      <td>2012-11-28</td>\n",
       "      <td>OR</td>\n",
       "      <td>15696</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32154</th>\n",
       "      <td>R</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>SC</td>\n",
       "      <td>15696</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32155</th>\n",
       "      <td>R</td>\n",
       "      <td>2013-05-29</td>\n",
       "      <td>OR</td>\n",
       "      <td>15696</td>\n",
       "      <td>0.63</td>\n",
       "      <td>R</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.200659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32233</th>\n",
       "      <td>R</td>\n",
       "      <td>2019-12-19</td>\n",
       "      <td>OR</td>\n",
       "      <td>15696</td>\n",
       "      <td>0.8</td>\n",
       "      <td>R</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.096910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32234</th>\n",
       "      <td>R</td>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>OR</td>\n",
       "      <td>15696</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32235</th>\n",
       "      <td>R</td>\n",
       "      <td>2020-02-27</td>\n",
       "      <td>OR</td>\n",
       "      <td>15696</td>\n",
       "      <td>0.8</td>\n",
       "      <td>R</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.096910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32236</th>\n",
       "      <td>R</td>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>OR</td>\n",
       "      <td>15696</td>\n",
       "      <td>0.8</td>\n",
       "      <td>R</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.096910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32237</th>\n",
       "      <td>R</td>\n",
       "      <td>2020-04-23</td>\n",
       "      <td>OR</td>\n",
       "      <td>15696</td>\n",
       "      <td>1.25</td>\n",
       "      <td>R</td>\n",
       "      <td>1.25</td>\n",
       "      <td>-0.096910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      laterality_raw study_date visual_acuity_origin  patient_id  \\\n",
       "32151              R 2012-08-17                   SC       15696   \n",
       "32152              R 2012-10-31                   SC       15696   \n",
       "32153              R 2012-11-28                   OR       15696   \n",
       "32154              R 2013-01-04                   SC       15696   \n",
       "32155              R 2013-05-29                   OR       15696   \n",
       "...              ...        ...                  ...         ...   \n",
       "32233              R 2019-12-19                   OR       15696   \n",
       "32234              R 2020-01-30                   OR       15696   \n",
       "32235              R 2020-02-27                   OR       15696   \n",
       "32236              R 2020-03-27                   OR       15696   \n",
       "32237              R 2020-04-23                   OR       15696   \n",
       "\n",
       "      visual_acuity_raw laterality visual_acuity  logMAR_raw  \n",
       "32151                 1          R         other         NaN  \n",
       "32152                 1          R         other         NaN  \n",
       "32153                 1          R         other         NaN  \n",
       "32154                 1          R         other         NaN  \n",
       "32155              0.63          R          0.63    0.200659  \n",
       "...                 ...        ...           ...         ...  \n",
       "32233               0.8          R           0.8    0.096910  \n",
       "32234                 1          R         other         NaN  \n",
       "32235               0.8          R           0.8    0.096910  \n",
       "32236               0.8          R           0.8    0.096910  \n",
       "32237              1.25          R          1.25   -0.096910  \n",
       "\n",
       "[87 rows x 8 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visus_labels_clean[(visus_labels_clean.patient_id == 15696) & (visus_labels_clean.laterality == \"R\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add logMAR_raw column (unmapped, no string values)\n",
    "visus_labels_clean['logMAR_raw'] = visus_labels_clean.visual_acuity.apply(to_logMAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>laterality_raw</th>\n",
       "      <th>study_date</th>\n",
       "      <th>visual_acuity_origin</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>visual_acuity_raw</th>\n",
       "      <th>laterality</th>\n",
       "      <th>visual_acuity</th>\n",
       "      <th>logMAR_raw</th>\n",
       "      <th>logMAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L</td>\n",
       "      <td>2014-03-19</td>\n",
       "      <td>SC</td>\n",
       "      <td>7</td>\n",
       "      <td>1/25</td>\n",
       "      <td>L</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.397940</td>\n",
       "      <td>1.397940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R</td>\n",
       "      <td>2014-03-19</td>\n",
       "      <td>SC</td>\n",
       "      <td>7</td>\n",
       "      <td>0,05</td>\n",
       "      <td>R</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.301030</td>\n",
       "      <td>1.301030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L</td>\n",
       "      <td>2015-01-22</td>\n",
       "      <td>OR</td>\n",
       "      <td>17</td>\n",
       "      <td>0.6</td>\n",
       "      <td>L</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.221849</td>\n",
       "      <td>0.221849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L</td>\n",
       "      <td>2015-12-10</td>\n",
       "      <td>SC</td>\n",
       "      <td>17</td>\n",
       "      <td>0.6</td>\n",
       "      <td>L</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.221849</td>\n",
       "      <td>0.221849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L</td>\n",
       "      <td>2016-01-29</td>\n",
       "      <td>OR</td>\n",
       "      <td>17</td>\n",
       "      <td>0.8</td>\n",
       "      <td>L</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.096910</td>\n",
       "      <td>0.096910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730075</th>\n",
       "      <td>R</td>\n",
       "      <td>2019-01-15</td>\n",
       "      <td>OR</td>\n",
       "      <td>384249</td>\n",
       "      <td>0.1</td>\n",
       "      <td>R</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730076</th>\n",
       "      <td>R</td>\n",
       "      <td>2019-05-31</td>\n",
       "      <td>OR</td>\n",
       "      <td>384249</td>\n",
       "      <td>0.1</td>\n",
       "      <td>R</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730077</th>\n",
       "      <td>R</td>\n",
       "      <td>2019-07-02</td>\n",
       "      <td>CC</td>\n",
       "      <td>384249</td>\n",
       "      <td>&lt;0.1</td>\n",
       "      <td>R</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730078</th>\n",
       "      <td>R</td>\n",
       "      <td>2019-08-27</td>\n",
       "      <td>SC</td>\n",
       "      <td>384249</td>\n",
       "      <td>0.05</td>\n",
       "      <td>R</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.301030</td>\n",
       "      <td>1.301030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730079</th>\n",
       "      <td>R</td>\n",
       "      <td>2019-11-05</td>\n",
       "      <td>SC</td>\n",
       "      <td>384249</td>\n",
       "      <td>0.16</td>\n",
       "      <td>R</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.795880</td>\n",
       "      <td>0.795880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>730080 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       laterality_raw study_date visual_acuity_origin  patient_id  \\\n",
       "0                   L 2014-03-19                   SC           7   \n",
       "1                   R 2014-03-19                   SC           7   \n",
       "2                   L 2015-01-22                   OR          17   \n",
       "3                   L 2015-12-10                   SC          17   \n",
       "4                   L 2016-01-29                   OR          17   \n",
       "...               ...        ...                  ...         ...   \n",
       "730075              R 2019-01-15                   OR      384249   \n",
       "730076              R 2019-05-31                   OR      384249   \n",
       "730077              R 2019-07-02                   CC      384249   \n",
       "730078              R 2019-08-27                   SC      384249   \n",
       "730079              R 2019-11-05                   SC      384249   \n",
       "\n",
       "       visual_acuity_raw laterality visual_acuity  logMAR_raw    logMAR  \n",
       "0                   1/25          L          0.04    1.397940  1.397940  \n",
       "1                   0,05          R          0.05    1.301030  1.301030  \n",
       "2                    0.6          L           0.6    0.221849  0.221849  \n",
       "3                    0.6          L           0.6    0.221849  0.221849  \n",
       "4                    0.8          L           0.8    0.096910  0.096910  \n",
       "...                  ...        ...           ...         ...       ...  \n",
       "730075               0.1          R           0.1    1.000000  1.000000  \n",
       "730076               0.1          R           0.1    1.000000  1.000000  \n",
       "730077              <0.1          R         other         NaN       NaN  \n",
       "730078              0.05          R          0.05    1.301030  1.301030  \n",
       "730079              0.16          R          0.16    0.795880  0.795880  \n",
       "\n",
       "[730080 rows x 9 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visus_labels_clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-inf,-0.4):\t302\n",
      "[-0.4,-0.2):\t898\n",
      "[-0.2,0.0):\t15657\n",
      "[0.0,0.2):\t266241\n",
      "[0.2,0.4):\t206860\n",
      "[0.4,0.6):\t32617\n",
      "[0.6,0.8):\t46829\n",
      "[0.8,1.0):\t6442\n",
      "[1.0,1.2):\t31409\n",
      "[1.2,1.4):\t13551\n",
      "[1.4,1.6):\t4822\n",
      "[1.6,1.8):\t1900\n",
      "[1.8,2.0):\t233\n",
      "[2.0,10.0):\t32\n",
      "[10.0,inf]:\t8\n",
      "FZ:\t\t7377\n",
      "HBW:\t\t20001\n",
      "FIX:\t\t1084\n",
      "LILO:\t\t7\n",
      "LUX:\t\t2735\n",
      "NL:\t\t3630\n"
     ]
    }
   ],
   "source": [
    "va_num = visus_labels_clean['logMAR_raw']\n",
    "va_str = visus_labels_clean['visual_acuity_raw']\n",
    "\n",
    "# print frequency of logMAR values and strings\n",
    "nums, bins = np.histogram(va_num, bins=np.concatenate([[-np.inf], np.arange(-0.4,2.1,0.2), [10, np.inf]]))\n",
    "for i, num in enumerate(nums[:-1]):\n",
    "    print('[{:.1f},{:.1f}):\\t{}'.format(bins[i], bins[i+1], nums[i]))\n",
    "print('[{:.1f},{:.1f}]:\\t{}'.format(bins[-2], bins[-1], nums[-1]))\n",
    "\n",
    "for s in ['FZ', 'HBW', 'FIX', 'LILO', 'LUX', 'NL']:\n",
    "    print('{}:\\t\\t{}'.format(s, sum(va_str==s)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "map logMAR and string values: (using values from https://michaelbach.de/sci/acuity.html)\n",
    "- logMAR < -0.3 gets mapped to -0.3\n",
    "- logMAR == inf gets mapped to value for NL (va 0 means blind!)\n",
    "- OLD: logMAR > 2.0 gets mapped to 2.0. This is not done anymore, values stay as is!\n",
    "- FZ (count fingers) gets mapped to 1.9\n",
    "- HBW gets mapped to 2.3 \n",
    "- FIX/LILO gets mapped to 2.6\n",
    "- LUX gets mapped to 2.8\n",
    "- NL gets mapped to 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "visus_labels_clean['logMAR'] = visus_labels_clean.logMAR_raw\n",
    "# mapping logMAR values\n",
    "visus_labels_clean.loc[visus_labels_clean.logMAR_raw<-0.3, 'logMAR'] = -0.3\n",
    "#visus_labels_clean.loc[visus_labels_clean.logMAR_raw>2.0, 'logMAR'] = 2.0\n",
    "visus_labels_clean.loc[visus_labels_clean.logMAR_raw==np.inf, 'logMAR'] = 3.0\n",
    "# string values\n",
    "visus_labels_clean.loc[visus_labels_clean.visual_acuity=='FZ', 'logMAR'] = 1.9\n",
    "visus_labels_clean.loc[visus_labels_clean.visual_acuity=='HBW', 'logMAR'] = 2.3\n",
    "visus_labels_clean.loc[visus_labels_clean.visual_acuity=='FIX', 'logMAR'] = 2.6\n",
    "visus_labels_clean.loc[visus_labels_clean.visual_acuity=='LILO', 'logMAR'] = 2.6\n",
    "visus_labels_clean.loc[visus_labels_clean.visual_acuity=='LUX', 'logMAR'] = 2.8\n",
    "visus_labels_clean.loc[visus_labels_clean.visual_acuity=='NL', 'logMAR'] = 3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match other measurements to potential CALCULATED Values\n",
    "\n",
    "As only na values were replaced by \"CALCULATED_VALUE\" or \"LOGMAR_VALUE\" or \"MEASUREMENT_VALUE\". \n",
    "\n",
    "Some none na values were not successfully parsed and transformed to logMAR, thus the below code\n",
    "replaces those we precomputed logMAR provided from the last export.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_meas_columns = [\"study_date\", \"patient_id\", \"laterality\", \"LOGMAR_VALUE\"]\n",
    "visus_labels_clean_ = pd.merge(visus_labels_clean, all_measurements[all_meas_columns].drop_duplicates(), \n",
    "                                 on=[\"study_date\", \"patient_id\", \"laterality\"], how=\"left\").drop_duplicates()\n",
    "\n",
    "visus_labels_clean_.loc[:, \"logMAR\"] = visus_labels_clean_.logMAR.fillna(visus_labels_clean_.LOGMAR_VALUE)\n",
    "\n",
    "visus_labels_clean_ = visus_labels_clean_[~visus_labels_clean_.logMAR.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>laterality_raw</th>\n",
       "      <th>study_date</th>\n",
       "      <th>visual_acuity_origin</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>visual_acuity_raw</th>\n",
       "      <th>laterality</th>\n",
       "      <th>visual_acuity</th>\n",
       "      <th>logMAR_raw</th>\n",
       "      <th>logMAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32151</th>\n",
       "      <td>R</td>\n",
       "      <td>2012-08-17</td>\n",
       "      <td>SC</td>\n",
       "      <td>15696</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32152</th>\n",
       "      <td>R</td>\n",
       "      <td>2012-10-31</td>\n",
       "      <td>SC</td>\n",
       "      <td>15696</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32153</th>\n",
       "      <td>R</td>\n",
       "      <td>2012-11-28</td>\n",
       "      <td>OR</td>\n",
       "      <td>15696</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32154</th>\n",
       "      <td>R</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>SC</td>\n",
       "      <td>15696</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32155</th>\n",
       "      <td>R</td>\n",
       "      <td>2013-05-29</td>\n",
       "      <td>OR</td>\n",
       "      <td>15696</td>\n",
       "      <td>0.63</td>\n",
       "      <td>R</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.200659</td>\n",
       "      <td>0.200659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32233</th>\n",
       "      <td>R</td>\n",
       "      <td>2019-12-19</td>\n",
       "      <td>OR</td>\n",
       "      <td>15696</td>\n",
       "      <td>0.8</td>\n",
       "      <td>R</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.096910</td>\n",
       "      <td>0.096910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32234</th>\n",
       "      <td>R</td>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>OR</td>\n",
       "      <td>15696</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>other</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32235</th>\n",
       "      <td>R</td>\n",
       "      <td>2020-02-27</td>\n",
       "      <td>OR</td>\n",
       "      <td>15696</td>\n",
       "      <td>0.8</td>\n",
       "      <td>R</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.096910</td>\n",
       "      <td>0.096910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32236</th>\n",
       "      <td>R</td>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>OR</td>\n",
       "      <td>15696</td>\n",
       "      <td>0.8</td>\n",
       "      <td>R</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.096910</td>\n",
       "      <td>0.096910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32237</th>\n",
       "      <td>R</td>\n",
       "      <td>2020-04-23</td>\n",
       "      <td>OR</td>\n",
       "      <td>15696</td>\n",
       "      <td>1.25</td>\n",
       "      <td>R</td>\n",
       "      <td>1.25</td>\n",
       "      <td>-0.096910</td>\n",
       "      <td>-0.096910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      laterality_raw study_date visual_acuity_origin  patient_id  \\\n",
       "32151              R 2012-08-17                   SC       15696   \n",
       "32152              R 2012-10-31                   SC       15696   \n",
       "32153              R 2012-11-28                   OR       15696   \n",
       "32154              R 2013-01-04                   SC       15696   \n",
       "32155              R 2013-05-29                   OR       15696   \n",
       "...              ...        ...                  ...         ...   \n",
       "32233              R 2019-12-19                   OR       15696   \n",
       "32234              R 2020-01-30                   OR       15696   \n",
       "32235              R 2020-02-27                   OR       15696   \n",
       "32236              R 2020-03-27                   OR       15696   \n",
       "32237              R 2020-04-23                   OR       15696   \n",
       "\n",
       "      visual_acuity_raw laterality visual_acuity  logMAR_raw    logMAR  \n",
       "32151                 1          R         other         NaN       NaN  \n",
       "32152                 1          R         other         NaN       NaN  \n",
       "32153                 1          R         other         NaN       NaN  \n",
       "32154                 1          R         other         NaN       NaN  \n",
       "32155              0.63          R          0.63    0.200659  0.200659  \n",
       "...                 ...        ...           ...         ...       ...  \n",
       "32233               0.8          R           0.8    0.096910  0.096910  \n",
       "32234                 1          R         other         NaN       NaN  \n",
       "32235               0.8          R           0.8    0.096910  0.096910  \n",
       "32236               0.8          R           0.8    0.096910  0.096910  \n",
       "32237              1.25          R          1.25   -0.096910 -0.096910  \n",
       "\n",
       "[87 rows x 9 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visus_labels_clean[(visus_labels_clean.patient_id == 15696) & (visus_labels_clean.laterality == \"R\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Integrate supplement table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print frequency of logMAR values and strings\n",
    "nums, bins = np.histogram(visus_labels_clean_.logMAR, bins=np.concatenate([[-np.inf], np.arange(-0.401,3.1,0.2), [np.inf]]))\n",
    "for i, num in enumerate(nums[:-1]):\n",
    "    print('[{:.3f},{:.3f}):\\t{}'.format(bins[i], bins[i+1], nums[i]))\n",
    "print('[{:.3f},{:.3f}]:\\t{}'.format(bins[-2], bins[-1], nums[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cleaned table\n",
    "visus_labels_clean_.to_csv(os.path.join(clean_data_dir, 'visus_labels_clean.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis = pd.read_csv(os.path.join(data_dir, 'diagnosis.csv'), index_col=0)\n",
    "print('Starting with {} measurements'.format(len(diagnosis)))\n",
    "\n",
    "# rename columns\n",
    "diagnosis.rename(columns={'LOK': 'laterality_raw', 'DAT':'study_date', 'PATNR':'patient_id', 'DKAT':'DKAT', 'DKEY':'diagnosis'}, inplace=True)\n",
    "\n",
    "# format columns \n",
    "diagnosis.study_date = pd.to_datetime(diagnosis.study_date)\n",
    "diagnosis.diagnosis = diagnosis.diagnosis.astype('str')\n",
    "\n",
    "# remove non-eye related diagnoses\n",
    "diagnosis['category'] = diagnosis.diagnosis.apply(lambda x: x[0])\n",
    "diagnosis = diagnosis[diagnosis.category == 'H']  # TODO need to include 'E' as well for diabetic retinopathy\n",
    "print('Starting with {} diagnoses of eye diseases'.format(len(diagnosis)))\n",
    "\n",
    "# removing duplicates\n",
    "diagnosis = diagnosis.drop_duplicates()\n",
    "print('After removing duplicates: {} diagnoses'.format(len(diagnosis)))\n",
    "\n",
    "# todo drop nan laterality diagnoses? \n",
    "# put duplicate diagnoses in list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load descriptions of diagnoses\n",
    "diagnosis_code = pd.read_csv(os.path.join(clean_data_dir, 'icd10cm_order_2018.txt'), sep='\\t', header=None)\n",
    "\n",
    "codes = []\n",
    "desc = []\n",
    "for i in range(len(diagnosis_code)):\n",
    "    code = diagnosis_code[0][i]\n",
    "    codes.append(code[6:14].strip())\n",
    "    desc.append(code[16:77].strip())\n",
    "    \n",
    "diagnosis_code['diagnosis'] = codes\n",
    "diagnosis_code['description'] = desc\n",
    "diagnosis_code = diagnosis_code[['diagnosis', 'description']]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistics\n",
    "diag = list(diagnosis['diagnosis'])\n",
    "diag_cl = []\n",
    "for d in diag:\n",
    "    if len(re.findall(r'H\\d\\d\\.\\d', d)) > 0:\n",
    "        diag_cl.append(d)\n",
    "        \n",
    "unique, counts = np.unique(diag_cl, return_counts=True)\n",
    "\n",
    "# sort by frequency\n",
    "unique_sorted = [x for _,x in sorted(zip(counts,unique), reverse=True)]\n",
    "counts_sorted = sorted(counts, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    desc = diagnosis_code[diagnosis_code.diagnosis==unique_sorted[i].replace('.','')].description\n",
    "    try:\n",
    "        desc = desc.iloc[0]\n",
    "    except IndexError:\n",
    "        desc = ''\n",
    "    print('{}: {}: {}'.format(counts_sorted[i], unique_sorted[i], desc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(counts_sorted)), [int(u) for u in counts_sorted])\n",
    "plt.xlim(0,200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process new confirmed diagnoses from Karsten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis_export_2 = pd.read_csv(os.path.join(longitudinal_dir, 'longitudinal_records_with_date_CHECKED.csv'), \n",
    "                                 index_col=0)\n",
    "\n",
    "diagnosis_export_2 = diagnosis_export_2.rename(columns={\"pseudo_id\": \"patient_id\", \n",
    "                                                        \"first_injection_date\": \"iol_date\",\n",
    "                                                        \"LOK\": \"laterality\"})\n",
    "\n",
    "diagnosis_export_2[\"DIAGNOSE0\"] = \"AMD\"\n",
    "diagnosis_export_2[\"DIAGNOSE1\"] = \"AMD\"\n",
    "diagnosis_export_2[\"diagnosis\"] = \"AMD\"\n",
    "diagnosis_export_2[\"diagnosis_raw\"] = \"AMD\"\n",
    "diagnosis_export_2[\"confirm\"] = 1\n",
    "diagnosis_export_2[\"AGE\"] = np.nan\n",
    "diagnosis_export_2[\"laterality_raw\"] = diagnosis_export_2.laterality\n",
    "\n",
    "diagnosis_export_2.drop(columns=[\"Note\", \"Naive\", \"Cat\", \"Cat-Date\", \"Unnamed: 9\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load left and right eye data frame from Karsten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis_left = pd.read_csv(os.path.join(longitudinal_dir, 'longitudinal_patients_left_eye.csv'), index_col=0)\n",
    "diagnosis_right = pd.read_csv(os.path.join(longitudinal_dir, 'longitudinal_patients_right_eye.csv'), index_col=0)\n",
    "\n",
    "\n",
    "# overwrite diagnosis from DWH to only analyse the longitudinal diagnosis records\n",
    "diagnosis = diagnosis_left.append(diagnosis_right, ignore_index=True)\n",
    "print('Starting with {} measurements'.format(len(diagnosis)))\n",
    "\n",
    "# rename columns\n",
    "diagnosis.rename(columns={'EYE': 'laterality_raw', 'Karsten':'diagnosis_raw', 'pseudo_id':'patient_id', 'IOL':'iol_date'}, inplace=True)\n",
    "# format columns \n",
    "diagnosis.iol_date = pd.to_datetime(diagnosis.iol_date)\n",
    "diagnosis.diagnosis_raw.loc[diagnosis.diagnosis_raw.isna()] = diagnosis.DIAGNOSE1.loc[diagnosis.diagnosis_raw.isna()]\n",
    "diagnosis['laterality'] = diagnosis.laterality_raw.str.upper()\n",
    "# add diagnosis column (only containing AMD and DR diagnosis for now)\n",
    "diagnosis['diagnosis'] = np.nan\n",
    "diagnosis.diagnosis.loc[diagnosis.diagnosis_raw.apply(lambda x: 'AMD' in x)] = 'AMD'\n",
    "diagnosis.diagnosis.loc[diagnosis.diagnosis_raw.apply(lambda x: 'Diabetisches' in x)] = 'DR'\n",
    "\n",
    "#diagnosis.diagnosis = diagnosis.diagnosis.astype('str')\n",
    "\n",
    "print('Have {} longitudinal eyes, {} of which have diagnosis AMD, and {} have DR'.format(\n",
    "    len(diagnosis), \n",
    "    (diagnosis.diagnosis == 'AMD').sum(), \n",
    "    (diagnosis.diagnosis == 'DR').sum()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load new longitudinal naive cases to be included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis_joint = pd.read_csv(os.path.join(longitudinal_dir, 'diagnosis_longitudinal_clean.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### merge new longitudinal records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis = diagnosis_export_2.append(diagnosis, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis.dropna(subset=[\"iol_date\"]).sort_values(\"patient_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis_joint.dropna(subset=[\"iol_date\"]).sort_values(\"patient_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# do not save this file as it contains not updated information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# save cleaned table\n",
    "diagnosis_joint.to_csv(os.path.join(clean_data_dir, 'diagnosis_longitudinal_clean.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procedures = pd.read_csv(os.path.join(data_dir, 'prozeduren.csv'), index_col=0)\n",
    "\n",
    "# rename columns\n",
    "procedures.rename(columns={'LOK': 'laterality_raw', 'DAT':'study_date', 'PATNR':'patient_id'}, inplace=True)\n",
    "# format columns \n",
    "procedures.study_date = pd.to_datetime(procedures.study_date)\n",
    "\n",
    "# duplicate entries for laterality=='B'\n",
    "procedures['laterality_raw'].fillna('B', inplace=True)\n",
    "procedures['laterality'] = procedures['laterality_raw']\n",
    "procedures.loc[procedures['laterality_raw'] == 'B', 'laterality'] = 'L'\n",
    "procedures_R = procedures.loc[procedures['laterality_raw'] == 'B'].copy().assign(laterality='R')\n",
    "procedures = procedures.append(procedures_R, ignore_index=True)\n",
    "\n",
    "# get rid of exact duplicates\n",
    "num_raw = procedures.shape[0]\n",
    "procedures = procedures.drop_duplicates(keep='first')\n",
    "num_raw_nodup = procedures.shape[0]\n",
    "print('Dropped {} exact duplicates'.format(num_raw-num_raw_nodup))\n",
    "\n",
    "# take care of duplicate measurements per time point\n",
    "num_dups = sum(procedures.duplicated(['study_date', 'patient_id', 'laterality']))\n",
    "print('Resolving {} duplicate measurements per time point'.format(num_dups))\n",
    "\n",
    "# remove everything not in chapter 5 08-16 (surgeries of the eye)\n",
    "procedures_filtered = procedures[procedures.ICPML.apply(lambda x: x[:4] in ['5-08','5-09','5-10','5-11','5-12','5-13','5-14','5-15','5-16'])]\n",
    "# reduce code to 3 decimals\n",
    "procedures_filtered.ICPML = procedures_filtered.loc[:,'ICPML'].apply(lambda x: x[:5])\n",
    "print('Number of filtered procedures {}'.format(len(procedures_filtered)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list most common procedures\n",
    "unique, counts = np.unique(list(procedures_filtered.ICPML), return_counts=True)\n",
    "unqiue = [u for _,u in sorted(zip(counts, unique), reverse=True)]\n",
    "counts = sorted(counts, reverse=True)\n",
    "\n",
    "for i in range(20):\n",
    "    print(unqiue[i], counts[i])\n",
    "    \n",
    "plt.plot(range(len(counts)), [int(u) for u in counts])\n",
    "plt.xlim(0,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "codes with highest occurrence:\n",
    "- 5-984 nicht relevant\n",
    "- 5-156.9 - Injektionen\n",
    "- 5-154 - Netzhautfixierung\n",
    "- 5-144 - Extrakapsuläre Extraktion der Linse\n",
    "- 5-158 - Vitrektomie\n",
    "- 5-985 - Lasertechnik, nicht relevant\n",
    "- 5-159 - Vitrektomie\n",
    "- 5-155 - Destruktion von erkranktem Gewebe an Retina und Choroidea\n",
    "- 5-010 - nicht relevant\n",
    "- 5-091 - Exzision und Destruktion von (erkranktem) Gewebe des Augenlides, nicht relevant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save procedures - not quite clean\n",
    "procedures_filtered.to_csv(os.path.join(clean_data_dir, 'procedures_clean.csv'))\n",
    "print('Saved {} procedures'.format(len(procedures_filtered)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procedures_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get OCT and fundus maps\n",
    "### OCTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "oct_meta_information = pd.read_csv(os.path.join(RAW_DIR,\"joint_export\", 'oct_meta_information.csv'))\n",
    "\n",
    "columns_oi = [\"PATNR\", \"laterality\", \"study_date\", \"oct_path\"]\n",
    "octs = oct_meta_information[columns_oi]\n",
    "\n",
    "# rename columns\n",
    "octs = octs.rename(columns={\"PATNR\":\"patient_id\"})\n",
    "\n",
    "# add non existing fundus path\n",
    "octs[\"fundus_path\"] = None\n",
    "\n",
    "print(\"Number of oct paths before dropping duplicates: \", octs.shape[0])\n",
    "\n",
    "# drop any duplicates\n",
    "octs_no_dups = octs.drop_duplicates(subset=[\"patient_id\", \"laterality\", \"study_date\"])\n",
    "\n",
    "print(\"Number of oct paths after dropping duplicates: \", octs_no_dups.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cleaned table\n",
    "octs.to_csv(os.path.join(clean_data_dir, 'octs_fundus_with_dups.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### explore OCTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_oct_slice(data_table, slice_no=24):\n",
    "    plt.figure()\n",
    "    plt.imshow(data_table.pixel_array[slice_no])\n",
    "    \n",
    "def interactive_show_oct_slice(data_table):\n",
    "    interact(show_oct_slice, \n",
    "             slice_no=widgets.IntSlider(min=0, max=48, step=1, value=24), \n",
    "             data_table=fixed(data_table))\n",
    "    \n",
    "def get_oct_data(d):\n",
    "    x_starts = []\n",
    "    y_starts = []\n",
    "    x_ends = []\n",
    "    y_ends = []\n",
    "    for i in range(0, len(d.PerFrameFunctionalGroupsSequence)):    \n",
    "        y_starts.append(d.PerFrameFunctionalGroupsSequence[i].OphthalmicFrameLocationSequence[0].ReferenceCoordinates[0] )\n",
    "        x_starts.append(d.PerFrameFunctionalGroupsSequence[i].OphthalmicFrameLocationSequence[0].ReferenceCoordinates[1] )\n",
    "        y_ends.append(d.PerFrameFunctionalGroupsSequence[i].OphthalmicFrameLocationSequence[0].ReferenceCoordinates[2] )\n",
    "        x_ends.append(d.PerFrameFunctionalGroupsSequence[i].OphthalmicFrameLocationSequence[0].ReferenceCoordinates[3] )\n",
    "    return y_starts, x_starts, y_ends, x_ends\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### duplicate OCTs\n",
    "- some are unreadable, or have the wrong format\n",
    "- of the duplicates, often one will be of the optical nerve and the other of the macula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "octs_nona = octs.dropna(subset=['patient_id', 'laterality', 'study_date'])\n",
    "\n",
    "idx_cols = ['patient_id', 'laterality', 'study_date']\n",
    "print('Have {} duplicated octs'.format(sum(octs_nona.duplicated(idx_cols))))\n",
    "\n",
    "dup_octs = octs_nona[octs_nona.duplicated(idx_cols, keep=False)]\n",
    "octs_grouped = dup_octs.groupby(idx_cols)\n",
    "oct_keys = octs_grouped.groups.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show exemplary octs and fundus images\n",
    "i=12\n",
    "cur_octs = octs_grouped.get_group(list(oct_keys)[i])\n",
    "\n",
    "fig, axes = plt.subplots(1, len(cur_octs))\n",
    "for i, ax in enumerate(axes):\n",
    "    f = np.zeros([768,768])\n",
    "    y_starts, x_starts, y_ends, x_ends = get_oct_data(read_file(cur_octs.iloc[i].oct_path))\n",
    "    for i in range(len(x_starts)):\n",
    "        ax.plot([x_starts[i],x_ends[i]],[y_starts[i], y_ends[i]], 'w')\n",
    "    # ax.imshow(f.pixel_array)\n",
    "for i in range(len(cur_octs)):\n",
    "    f = read_file(cur_octs.iloc[i].oct_path)\n",
    "    interactive_show_oct_slice(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### non duplicate OCTs\n",
    "are they mostly of the macula? or are there also some of the optic nerve?\n",
    "- seem to be macular octs only\n",
    "- need to identify macular oct amongst duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodup_octs = octs_nona.drop_duplicates(idx_cols, keep=False)\n",
    "print('Have {} non-duplicated octs'.format(len(nodup_octs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nodup_octs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show exemplary octs and fundus images\n",
    "i=np.random.randint(0,len(nodup_octs))\n",
    "print(i)\n",
    "cur = nodup_octs.iloc[i]\n",
    "\n",
    "# f = read_file(cur.fundus_path)\n",
    "d = read_file(cur.oct_path)\n",
    "y_starts, x_starts, y_ends, x_ends = get_oct_data(d)\n",
    "for i in range(len(x_starts)):\n",
    "    plt.plot([x_starts[i],x_ends[i]],[y_starts[i], y_ends[i]], 'w')\n",
    "# plt.imshow(f.pixel_array)\n",
    "plt.show()\n",
    "interactive_show_oct_slice(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deal with duplicate octs\n",
    "... by throwing them out\n",
    "- in the future, might need to come back to this and do sth more advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodup_octs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cleaned table\n",
    "octs_no_dups.to_csv(os.path.join(clean_data_dir, 'octs_fundus_no_dups.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensio\n",
    "\n",
    "- from old notebook, untested\n",
    "- drop exact duplicates\n",
    "- take last measurement for duplicate measurements at the same day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensio = pd.read_csv(os.path.join(data_dir, 'dwh_tables/tensio.csv'), index_col=0)\n",
    "\n",
    "# rename columns\n",
    "#tensio.rename(columns={'AUGE': 'laterality', 'DAT':'study_date', 'PATNR':'patient_id',\n",
    "                            'TENSIO': 'tensio'}, inplace=True)\n",
    "# format columns \n",
    "#tensio.study_date = pd.to_datetime(tensio.study_date)\n",
    "#tensio.tensio = [float(t.replace(',','.')) for t in tensio.tensio]\n",
    "\n",
    "# get rid of exact duplicates\n",
    "#num_raw = tensio.shape[0]\n",
    "#tensio = tensio.drop_duplicates(keep='first')\n",
    "#num_raw_nodup = tensio.shape[0]\n",
    "#print('Dropped {} exact duplicates'.format(num_raw-num_raw_nodup))\n",
    "\n",
    "# take care of duplicate measurements per time point\n",
    "#num_dups = sum(tensio.duplicated(['study_date', 'patient_id', 'laterality']))\n",
    "#print('Resolving {} duplicate measurements per time point'.format(num_dups))\n",
    "\n",
    "#tensio_clean = tensio[~tensio.duplicated(['study_date', 'patient_id', 'laterality'], keep='last')]\n",
    "#tensio_clean.to_csv(os.path.join(workspace_path, 'tensio_clean.csv'))\n",
    "#print('Saved {} records to workspace'.format(len(tensio_clean)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2_super",
   "language": "python",
   "name": "tf2_super"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
