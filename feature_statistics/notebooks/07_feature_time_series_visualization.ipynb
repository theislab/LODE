{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pydicom import read_file\n",
    "import copy\n",
    "import sys\n",
    "import glob\n",
    "from copy import deepcopy\n",
    "from scipy import stats\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import tqdm \n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "PROJ_DIR = \"/home/olle/PycharmProjects/LODE\"\n",
    "\n",
    "sys.path.insert(0, os.path.join(PROJ_DIR, 'feature_statistics/utils'))\n",
    "\n",
    "import statistics_utils as su\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "WORK_SPACE = \"/home/olle/PycharmProjects/LODE/workspace\"\n",
    "\n",
    "oct_meta_pd = pd.read_csv(os.path.join(WORK_SPACE, \"joint_export/export_tables/oct_meta_information.csv\"))\n",
    "\n",
    "oct_meta_pd.loc[:, \"sequence\"] = oct_meta_pd.PATNR.astype(str) + \"_\" + oct_meta_pd.laterality\n",
    "\n",
    "data_pd = pd.read_csv( os.path.join(WORK_SPACE, \n",
    "                                    \"joint_export/longitudinal_properties_naive.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filter and preprocess data tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of filtered sequences for 3 months are: 337\n",
      "Number of filtered sequences for 6 months are: 361\n",
      "Number of filtered sequences for 12 months are: 332\n"
     ]
    }
   ],
   "source": [
    "filter_1, filter_3, filter_6, filter_12 = su.filter_time_ranges(data_pd)\n",
    "\n",
    "data_pd = su.preprocess_dataframe(data_pd, oct_meta_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rename lens surgery columns and convert types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pd = data_pd.rename(columns={\"lens_surgery_1\":\"cataract_surgery_before_sequence\",\n",
    "                        \"lens_surgery_3\":\"cataract_surgery_3\",\n",
    "                        \"lens_surgery_6\":\"cataract_surgery_6\",\n",
    "                        \"lens_surgery_12\":\"cataract_surgery_12\",\n",
    "                        \"lens_surgery_24\":\"cataract_surgery_24\",})\n",
    "\n",
    "columns_surgery = [\n",
    "                   \"cataract_surgery_before_sequence\", \n",
    "                   \"cataract_surgery_3\", \n",
    "                   \"cataract_surgery_6\", \n",
    "                   \"cataract_surgery_12\", \n",
    "                   \"cataract_surgery_24\"\n",
    "                  ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do type conversion\n",
    "for c in columns_surgery[1:]:\n",
    "    data_pd.loc[:, c] = data_pd[c].map({'False':0, 'True': 1}).astype(float).apply(np.ceil).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create data visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_features = [\"epm\", \"irf\", \"srf\", \"srhm\", \"rpe\", \"fvpde\", \"drusen\", \"phm\", \"choroid\", \"fibrosis\", \n",
    "               \"atropypercentage\", \"thicknessmean\"]\n",
    "\n",
    "seg_delta = []\n",
    "seg_times = [1, 3, 12]\n",
    "\n",
    "assert su.assert_times(seg_times), \"Selected time points contains not allowed values\"\n",
    "\n",
    "seg_independents = su.get_seg_independents_str(seg_features, seg_delta, seg_times)\n",
    "\n",
    "va_delta = []\n",
    "va_times = [1, 3, 12]\n",
    "\n",
    "assert su.assert_times(va_times), \"Selected time points contains not allowed values\"\n",
    "\n",
    "va_independents = su.get_va_dependents_str(va_delta, va_times)\n",
    "\n",
    "injection_times = [3]\n",
    "\n",
    "assert su.assert_times(injection_times), \"Selected time points contains not allowed values\"\n",
    "\n",
    "injection_independents = []\n",
    "for it in injection_times:\n",
    "    injection_independents.append(f\"n_injections_{it}\")\n",
    "    \n",
    "time_filters = {1: filter_1, 3: filter_3, 6: filter_6, 12: filter_12}\n",
    "\n",
    "\n",
    "abt = su.associate_time_n_factors(table=data_pd, spatial_sum=True, time_filters=time_filters, \n",
    "                               times=[1, 3, 12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sequence\n",
       "18_R        0.0\n",
       "502_L       0.0\n",
       "709_L       0.0\n",
       "1475_L      0.0\n",
       "1475_R      0.0\n",
       "           ... \n",
       "380400_R    0.0\n",
       "381618_L    0.0\n",
       "382403_L    0.0\n",
       "383182_L    0.0\n",
       "383602_L    0.0\n",
       "Name: thicknessmean_1, Length: 227, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abt.thicknessmean_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seg_features = [\"epm\", \"irf\", \"srf\", \"srhm\", \"rpe\", \"fvpde\", \"drusen\", \"phm\", \"choroid\", \"fibrosis\", \n",
    "               \"atropypercentage\", \"thicknessmean\"]\n",
    "\n",
    "seg_delta = []\n",
    "seg_times = [1, 3, 12]\n",
    "\n",
    "assert su.assert_times(seg_times), \"Selected time points contains not allowed values\"\n",
    "\n",
    "seg_independents = su.get_seg_independents_str(seg_features, seg_delta, seg_times)\n",
    "\n",
    "va_delta = []\n",
    "va_times = [1, 3, 12]\n",
    "\n",
    "assert su.assert_times(va_times), \"Selected time points contains not allowed values\"\n",
    "\n",
    "va_independents = su.get_va_dependents_str(va_delta, va_times)\n",
    "\n",
    "injection_times = [3]\n",
    "\n",
    "assert su.assert_times(injection_times), \"Selected time points contains not allowed values\"\n",
    "\n",
    "injection_independents = []\n",
    "for it in injection_times:\n",
    "    injection_independents.append(f\"n_injections_{it}\")\n",
    "    \n",
    "time_filters = {1: filter_1, 3: filter_3, 6: filter_6, 12: filter_12}\n",
    "\n",
    "\n",
    "abt = su.associate_time_n_factors(table=data_pd, spatial_sum=True, time_filters=time_filters, \n",
    "                               times=[1, 3, 12])\n",
    "\n",
    "abt.loc[:, \"thicknessmean_1\"] = abt.thicknessmean_1 / 9.\n",
    "abt.loc[:, \"thicknessmean_3\"] = abt.thicknessmean_3 / 9.\n",
    "abt.loc[:, \"thicknessmean_12\"] = abt.thicknessmean_12 / 9.\n",
    "\n",
    "abt_spatial = su.associate_time_n_factors(table=data_pd, spatial_sum=False, time_filters=time_filters,\n",
    "                                       times=[1, 3, 12])\n",
    "\n",
    "seg_indeps = []\n",
    "for segtime in seg_times:\n",
    "    seg_indeps.extend(abt.loc[:, ~abt.columns.str.contains(\"15\")].columns.values.tolist())\n",
    "        \n",
    "# filter out va columns\n",
    "# seg_indeps = [i for i in seg_indeps if \"va\" not in i]\n",
    "#seg_indeps = [i for i in seg_indeps if \"injections\" not in i]\n",
    "seg_indeps = [i for i in seg_indeps if \"delta\" not in i]\n",
    "\n",
    "\n",
    "independent_variables = injection_independents + seg_indeps + [\"cur_va_rounded_1\"]\n",
    "\n",
    "abt_viz = abt[independent_variables]\n",
    "\n",
    "# drop duplicate columns\n",
    "abt_viz = abt_viz.loc[:,~abt_viz.columns.duplicated()]\n",
    "\n",
    "# add all first order interactions\n",
    "columns = copy.copy(abt_viz.columns)\n",
    "            \n",
    "indep_vars_interactions = list(abt_viz.columns)\n",
    "\n",
    "abt_viz[\"va_change\"] = abt.cur_va_rounded_12 - abt.cur_va_rounded_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pd.iloc[:, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_sum = data_pd.columns.str.endswith(\"_1_12\")\n",
    "\n",
    "data_pd.iloc[:, col_to_sum].sum(1) * 0.003872"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abt.thicknessmean_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## join in cataract information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_merge = ['cataract_surgery_before_sequence', 'cataract_surgery_3',\n",
    "       'cataract_surgery_6', 'cataract_surgery_12', 'cataract_surgery_24', \"sequence\"]\n",
    "\n",
    "abt_viz = pd.merge(abt_viz, data_pd[cols_to_merge], left_on=\"sequence\", right_on=\"sequence\", how=\"left\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of eyes with cataract before\", data_pd.cataract_surgery_before_sequence.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"number of eyes with cataract before\", data_pd.cataract_surgery_before_sequence.sum())\n",
    "print(\"number of eyes with cataract 3\", data_pd.cataract_surgery_3.sum())\n",
    "print(\"number of eyes with cataract 6\", data_pd.cataract_surgery_6.sum())\n",
    "print(\"number of eyes with cataract 12\", data_pd.cataract_surgery_12.sum())\n",
    "print(\"number of eyes with cataract 24\", data_pd.cataract_surgery_24.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"number of eyes with cataract before\", abt_viz.cataract_surgery_before_sequence.sum())\n",
    "print(\"number of eyes with cataract 3\", abt_viz.cataract_surgery_3.sum())\n",
    "print(\"number of eyes with cataract 6\", abt_viz.cataract_surgery_6.sum())\n",
    "print(\"number of eyes with cataract 12\", abt_viz.cataract_surgery_12.sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merge in age and gender information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oct_meta_pd_sub = oct_meta_pd[oct_meta_pd.sequence.isin(list(abt_viz.sequence))].drop_duplicates(subset=[\"sequence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oct_meta_pd_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "abt_viz = pd.merge(abt_viz, oct_meta_pd_sub[[\"sequence\", \"gender\", \"age\"]].drop_duplicates(), \n",
    "                   on=\"sequence\", how=\"left\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get base statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abt_viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean age: \", np.mean(abt_viz.age), np.std(abt_viz.age))\n",
    "print(\"sex distribution: \", np.unique(abt_viz.gender, return_counts=1))\n",
    "print(\"injection month 3: \", np.mean(abt_viz.n_injections_3), np.std(abt_viz.n_injections_3))\n",
    "print(\"injections month 12: \", np.mean(abt_viz.n_injections_12), np.std(abt_viz.n_injections_12))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_dict(feature, time_point, data_pd, feature_change, time_filters, spatial_sum=True):\n",
    "    data_temp = su.associate_time_n_factors(table=data_pd, spatial_sum=spatial_sum, time_filters=time_filters,\n",
    "                                         times=[1, time_point])\n",
    "    \n",
    "    # calc feature delta\n",
    "    feature_delta = data_temp[f\"{feature}_{time_point}\"] - data_temp[f\"{feature}_{1}\"]\n",
    "    \n",
    "    # get data points for feature increase or decrease cases\n",
    "    if feature_change == \"increase\":\n",
    "        data_temp = data_temp[feature_delta >= 0]\n",
    "    else:\n",
    "        data_temp = data_temp[feature_delta < 0]\n",
    "        \n",
    "    feature_columns = data_temp[[f\"{feature}_{time_point}\"]]\n",
    "    feature_columns.loc[:, \"va_change\"] = data_temp[f\"cur_va_rounded_{time_point}\"] - data_temp[\"cur_va_rounded_1\"]\n",
    "\n",
    "    feature_columns[\"va_class\"] = None\n",
    "    feature_columns[\"va_class\"][feature_columns.va_change > 0.15] = 0\n",
    "    feature_columns[\"va_class\"][(feature_columns.va_change > -0.15) & (feature_columns.va_change <= 0.15)] = 1\n",
    "    feature_columns[\"va_class\"][feature_columns.va_change <= -0.15] = 2\n",
    "    \n",
    "    n_injections = np.round(data_temp[f\"n_injections_{time_point}\"].mean(),2)\n",
    "    \n",
    "    dict_ = dict(feature_columns.va_class.value_counts())\n",
    "    dict_[f\"injections\"] = n_injections\n",
    "    return dict_\n",
    "\n",
    "def plot_stacked_bar(viz_dict, time, x_pos):\n",
    "    \n",
    "    lost = np.array([viz_dict[time][0]])\n",
    "    no_change = np.array([viz_dict[time][1]])\n",
    "    gained = np.array([viz_dict[time][2]])\n",
    "\n",
    "    # memo of sample number\n",
    "    snum = lost+no_change+gained\n",
    "\n",
    "    # normalization\n",
    "    y1 = lost/snum*100.\n",
    "    y2 = no_change/snum*100.\n",
    "    y3 = gained/snum*100.\n",
    "    \n",
    "    width = 0.2\n",
    "    \n",
    "    # stack bars\n",
    "    plt.bar(x_pos, y1, color=\"tab:red\", width=width)\n",
    "    plt.bar(x_pos, y2 , bottom=y1, color=\"tab:blue\", width=width)\n",
    "    plt.bar(x_pos, y3 , bottom=y1+y2, color=\"tab:green\", width=width)\n",
    "\n",
    "    # add text annotation corresponding to the percentage of each data.\n",
    "    for xpos, ypos, yval in zip([x_pos], y1/2, y1):\n",
    "        plt.text(xpos, ypos, \"%.1f\"%yval, ha=\"center\", va=\"center\")\n",
    "    for xpos, ypos, yval in zip([x_pos], y1+y2/2, y2):\n",
    "        plt.text(xpos, ypos, \"%.1f\"%yval, ha=\"center\", va=\"center\")\n",
    "    for xpos, ypos, yval in zip([x_pos], y1+y2+y3/2, y3):\n",
    "        plt.text(xpos, ypos, \"%.1f\"%yval, ha=\"center\", va=\"center\")\n",
    "    \n",
    "    # add text annotation corresponding to the \"total\" value of each bar\n",
    "    for xpos, ypos, yval in zip([x_pos], y1+y2+y3, snum):\n",
    "        plt.text(xpos, ypos, \"N=%d\"%yval, ha=\"center\", va=\"bottom\")\n",
    "        plt.text(xpos, ypos + 4, \"mean_inj=%d\"%viz_dict[time][\"injections\"], ha=\"center\", va=\"bottom\")\n",
    "\n",
    "    plt.ylim(0,110)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot 1 Feature distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add special features\n",
    "abt_viz = pd.merge(abt_viz, abt_spatial[[\"C0-choroid_1\", \n",
    "                                         \"C0-choroid_3\", \n",
    "                                         \"C0-choroid_12\"]], on=\"sequence\")\n",
    "\n",
    "cataract_f = abt_viz[~abt_viz.cataract_surgery_12.fillna(0).astype(bool)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = [\"thicknessmean\", \"C0-choroid\", \"irf\", \"rpe\", \"srf\", \"srhm\", \"fvpde\", \"fibrosis\", \"drusen\"]\n",
    "\n",
    "time_feature_list = []\n",
    "time_points = [1, 3, 12]\n",
    "for time in time_points:\n",
    "    for feature in feature_list:\n",
    "        time_feature_list.append(f\"{feature}_{time}\")\n",
    "        \n",
    "plot1_ = [i for i in cataract_f.columns.tolist() if i in time_feature_list]\n",
    "\n",
    "plot1_abt = cataract_f[plot1_ + [\"cataract_surgery_before_sequence\"]]\n",
    "\n",
    "plot1_abt.loc[:, \"cataract_surgery_before_sequence\"] = plot1_abt.cataract_surgery_before_sequence.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot1_abt.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check examples\n",
    "feature = \"thicknessmean\"\n",
    "sequence = \"15425_R\"\n",
    "seq_pd = cataract_f[cataract_f.sequence == sequence]\n",
    "feature_cols = [\"sequence\"] + [col for col in seq_pd.columns.tolist() if feature in col]\n",
    "\n",
    "seq_pd[feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_mapping = {\"bg\": (\"background\", [148., 158., 167.]),\n",
    "                 \"epm\": (\"epiretinal membrane\", [11., 151., 199.]),\n",
    "                 \"nsr\":(\"neurosensory retina\", [30., 122., 57.]),\n",
    "                 \"irf\": (\"intra retinal fluid\", [135., 191., 234.]),\n",
    "                 \"srf\":(\"sub retinal fluid\", [37., 111., 182.]),\n",
    "                 \"srhm\": (\"sub retinal hyp. material\", [156., 99., 84.]),\n",
    "                 \"rpe\": (\"RPE\", [226., 148., 60.]),\n",
    "                 \"fvpde\": (\"fibrovascular PED\", [203., 54., 68.]),\n",
    "                 \"drusen\": (\"drusen\", [192., 194., 149.]),\n",
    "                 \"phm\":(\"post. hylaoid membrane\", [105., 194., 185.]),\n",
    "                 \"choroid\": (\"choroid\", [205., 205., 205.]),\n",
    "                 \"serous_ped\": (\"serous PED\", [140., 204., 177.]),  # Serous PED\n",
    "                 \"other_artifact\": (\"other artifact\", [183., 186., 219.]),  # other artifact\n",
    "                 \"fibrosis\":(\"fibrosis\", [114, 137, 218]),  # fibrosis\n",
    "                 \"vitreous\": (\"vitreous\", [209., 227., 239.]),\n",
    "                 \"camera_effect\": (\"camera effect\", [226., 233., 48.])}\n",
    "\n",
    "\n",
    "# normalite colors\n",
    "color_mapping_norm = {}\n",
    "for key in color_mapping.keys():\n",
    "    color = color_mapping[key][1]\n",
    "    color_norm = [c / 255. for c in color]\n",
    "    color_mapping_norm[key] = (color_mapping[key][0], color_norm)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot1_abt_long[thickness_][\"cubim mm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.4)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "plot1_abt_long = plot1_abt.melt(id_vars=[\"cataract_surgery_before_sequence\"])\n",
    "\n",
    "plot1_abt_long.loc[:, \"time\"] = plot1_abt_long.variable.str.split(\"_\", expand=True)[1]\n",
    "plot1_abt_long.loc[:, \"feature\"] = plot1_abt_long.variable.str.split(\"_\", expand=True)[0]\n",
    "\n",
    "small_ = plot1_abt_long.feature.isin([\"irf\", \"srhm\", \"drusen\", \"fibrosis\"])\n",
    "large_ = plot1_abt_long.feature.isin([\"fvpde\", \"rpe\", \"C0-choroid\", \"srf\"])\n",
    "thickness_ = plot1_abt_long.feature.isin([\"thicknessmean\"])\n",
    "\n",
    "cataract_surgery = plot1_abt_long.cataract_surgery_before_sequence == 1.0\n",
    "\n",
    "plot1_abt_long = plot1_abt_long.rename(columns={\"value\":\"cubim mm\"})\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 7))\n",
    "\n",
    "table_small = plot1_abt_long[small_]\n",
    "g0 = sns.boxplot(x=\"feature\", y=\"cubim mm\", hue=\"time\",\n",
    "            data=table_small, \n",
    "            showfliers=False, ax=axes[0],\n",
    "            palette=[\"black\", \"darkgrey\", \"darkblue\"]);\n",
    "\n",
    "g0.set(xticks=[0,1,2,3])\n",
    "g0.set_xticklabels(['intra retinal fluid','sub retinal hyp. material',\n",
    "                    'drusen','fibrosis'], rotation=90)\n",
    "\n",
    "axes[0].set_ylabel(\"cubic micro meter\")\n",
    "\n",
    "\n",
    "g1 = sns.boxplot(x=\"feature\", y=\"cubim mm\", hue=\"time\",\n",
    "            data=plot1_abt_long[thickness_], \n",
    "            showfliers=False, ax=axes[1],\n",
    "            palette=[\"black\", \"darkgrey\", \"darkblue\"]);\n",
    "\n",
    "\n",
    "axes[1].set_ylabel(\"micro meter\")\n",
    "\n",
    "g1.set(xticks=[0])\n",
    "g1.set_xticklabels(['foveal thickness'], rotation=90)\n",
    "\n",
    "g2 = sns.boxplot(x=\"feature\", y=\"cubim mm\",\n",
    "            hue=\"time\",\n",
    "            data=plot1_abt_long[large_], \n",
    "            showfliers=False, ax=axes[2],\n",
    "            palette=[\"black\", \"darkgrey\", \"darkblue\"]);\n",
    "\n",
    "\n",
    "g2.set(xticks=[0,1,2, 3])\n",
    "g2.set_xticklabels(['sub retinal fluid', 'RPE','fibro vascular PED','foveal choroid'], rotation=90)\n",
    "\n",
    "g0.legend([])\n",
    "g1.legend([])\n",
    "g2.legend([])\n",
    "\n",
    "g0.set_ylim(0, 0.1)\n",
    "g1.set_ylim(0, 0.5)\n",
    "g2.set_ylim(0, 0.5)\n",
    "\n",
    "axes[2].set_ylabel(\"cubic micro meter\")\n",
    "\n",
    "axes[0].set_xlabel(\"\")\n",
    "axes[1].set_xlabel(\"\")\n",
    "axes[2].set_xlabel(\"\")\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "black_patch = mpatches.Patch(color='black', label='0')\n",
    "grey_patch = mpatches.Patch(color='darkgrey', label='3')\n",
    "darkblue_patch = mpatches.Patch(color='darkblue', label='12')\n",
    "\n",
    "plt.legend(title=\"month\", handles=[black_patch, grey_patch, darkblue_patch])\n",
    "\n",
    "#plt.suptitle(\"OCT bio marker change under antiVEGF treatment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot 2 Time until dry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluid_1 = abt_viz[[\"irf_1\", \"srf_1\"]].sum(1)\n",
    "fluid_3 = abt_viz[[\"irf_3\", \"srf_3\"]].sum(1)\n",
    "fluid_12 = abt_viz[[\"irf_12\", \"srf_12\"]].sum(1)\n",
    "\n",
    "print(f\"Number of dry eyes a time point 1: {sum(fluid_1 == 0)}\")\n",
    "print(f\"Number of dry eyes a time point 3: {sum(fluid_3 == 0)}\")\n",
    "print(f\"Number of dry eyes a time point 12: {sum(fluid_12== 0) }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "\n",
    "matplotlib.rc('xtick', labelsize=20) \n",
    "matplotlib.rc('ytick', labelsize=20) \n",
    "\n",
    "feature = \"thicknessmean\"\n",
    "spatial_sum = True\n",
    "\n",
    "cataract_bool = (data_pd.cataract_surgery_3 > 0) | (data_pd.cataract_surgery_6 > 0) | \\\n",
    "(data_pd.cataract_surgery_12 > 0)\n",
    "\n",
    "data_f_pd = data_pd[~cataract_bool]\n",
    "\n",
    "viz_dict_increased = {}\n",
    "\n",
    "viz_dict_increased[\"3\"] = get_time_dict(feature, 3, data_f_pd, feature_change=\"increase\", \n",
    "                                        time_filters=time_filters,\n",
    "                                        spatial_sum=spatial_sum)\n",
    "viz_dict_increased[\"6\"] = get_time_dict(feature, 6, data_f_pd, feature_change=\"increase\", \n",
    "                                        time_filters=time_filters,\n",
    "                                        spatial_sum=spatial_sum)\n",
    "viz_dict_increased[\"12\"] = get_time_dict(feature, 12, data_f_pd, feature_change=\"increase\", \n",
    "                                         time_filters=time_filters,\n",
    "                                         spatial_sum=spatial_sum)\n",
    "\n",
    "viz_dict_decreased = {}\n",
    "viz_dict_decreased[\"3\"] = get_time_dict(feature, 3, data_f_pd, feature_change=\"decrease\", \n",
    "                                        time_filters=time_filters,\n",
    "                                        spatial_sum=spatial_sum)\n",
    "viz_dict_decreased[\"6\"] = get_time_dict(feature, 6, data_f_pd, feature_change=\"decrease\", \n",
    "                                        time_filters=time_filters,\n",
    "                                        spatial_sum=spatial_sum)\n",
    "viz_dict_decreased[\"12\"] = get_time_dict(feature, 12, data_f_pd, feature_change=\"decrease\", \n",
    "                                         time_filters=time_filters,\n",
    "                                         spatial_sum=spatial_sum)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,14))\n",
    "\n",
    "plot_stacked_bar(viz_dict_decreased, time=\"3\", x_pos=1 - 0.2)\n",
    "plot_stacked_bar(viz_dict_decreased, time=\"6\", x_pos=2 - 0.2)\n",
    "plot_stacked_bar(viz_dict_decreased, time=\"12\", x_pos=3 - 0.2)\n",
    "\n",
    "plot_stacked_bar(viz_dict_increased, time=\"3\", x_pos=1 + 0.2)\n",
    "plot_stacked_bar(viz_dict_increased, time=\"6\", x_pos=2 + 0.2)\n",
    "plot_stacked_bar(viz_dict_increased, time=\"12\", x_pos=3 + 0.2)\n",
    "\n",
    "red_patch = mpatches.Patch(color='tab:red', label='lost')\n",
    "blue_patch = mpatches.Patch(color='tab:blue', label='no change')\n",
    "green_patch = mpatches.Patch(color='tab:green', label='gained')\n",
    "\n",
    "plt.legend(handles=[red_patch, blue_patch, green_patch], bbox_to_anchor=(1.02,0.5), loc='center left',\n",
    "          prop={'size': 20})\n",
    "\n",
    "space = \"                  \"\n",
    "plt.xticks([1,2,3], labels=[f\"-{feature}{space}+{feature}\\n3\", \n",
    "                            f\"-{feature}{space}+{feature}\\n6\", \n",
    "                            f\"-{feature}{space}+{feature}\\n12\"])\n",
    "\n",
    "plt.ylabel(\"% of eyes\", size=30)\n",
    "plt.xlabel(f\"month & increase / decrease of {feature}\", size=30)\n",
    "plt.title(f\"distribution of {feature} among eyes with increased, decreased \\n and unchanged visual acuity\",\n",
    "         size=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simple statistics for paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Number of eyes recieving Anti-VEGF\n",
    "\n",
    "cumsum_injections = abt_viz.n_injections_3 + abt_viz.n_injections_12\n",
    "\n",
    "print(\"number of patients recieving anti-VEGF\", np.sum(cumsum_injections > 0))\n",
    "\n",
    "# treatment start & end dates\n",
    "min_ = data_pd[filter_1 & filter_3 & filter_12].study_date_1.min()\n",
    "max_ = data_pd[filter_1 & filter_3 & filter_12].study_date_12.max()\n",
    "\n",
    "print(\"first treatment was: \", min_, \"last treatment was: \", max_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## print statistics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot1_abt.loc[:, \"C0-thicknessmean_1\"] = plot1_abt.loc[:, \"C0-thicknessmean_1\"] * 1000\n",
    "plot1_abt.loc[:, \"C0-thicknessmean_3\"] = plot1_abt.loc[:, \"C0-thicknessmean_3\"] * 1000\n",
    "plot1_abt.loc[:, \"C0-thicknessmean_12\"] = plot1_abt.loc[:, \"C0-thicknessmean_12\"] * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot1_abt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_features = [\n",
    "                \"epm\", \n",
    "                \"irf\", \n",
    "                \"srf\", \n",
    "                \"srhm\", \n",
    "                \"rpe\", \n",
    "                \"fvpde\", \n",
    "                \"drusen\", \n",
    "                \"phm\", \n",
    "                \"choroid\", \n",
    "                \"fibrosis\", \n",
    "                \"atropypercentage\", \n",
    "                \"thicknessmean\"\n",
    "               ]\n",
    "\n",
    "seg_times = [1, 3, 12]\n",
    "\n",
    "stats_log = {}\n",
    "\n",
    "for feature in seg_features:\n",
    "    stats_log[feature] = {}\n",
    "    for time in seg_times:\n",
    "        if feature == \"C0-thicknessmean\":\n",
    "            stats_log[feature][f\"mean_{time}\"] = abt_viz.loc[:, f\"{feature}_{time}\"].mean()\n",
    "            stats_log[feature][f\"std_{time}\"] = abt_viz.loc[:, f\"{feature}_{time}\"].std()\n",
    "        else:\n",
    "            stats_log[feature][f\"mean_{time}\"] = abt_viz.loc[:, f\"{feature}_{time}\"].mean()\n",
    "            stats_log[feature][f\"std_{time}\"] = abt_viz.loc[:, f\"{feature}_{time}\"].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test for stat significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abt_viz['thicknessmean_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "for feature in seg_features:\n",
    "    \n",
    "    stats_log[feature] = {}\n",
    "    rvs1 = abt_viz.loc[:, f\"{feature}_{1}\"]\n",
    "    rvs3 = abt_viz.loc[:, f\"{feature}_{3}\"]\n",
    "    rvs12 = abt_viz.loc[:, f\"{feature}_{12}\"]\n",
    "    \n",
    "    if feature == \"thicknessmean\":\n",
    "        print()\n",
    "        rvs1 = abt_viz.loc[:, f\"{feature}_{1}\"] * 1000\n",
    "        rvs3 = abt_viz.loc[:, f\"{feature}_{3}\"] * 1000\n",
    "        rvs12 = abt_viz.loc[:, f\"{feature}_{12}\"] * 1000\n",
    "\n",
    "    stats_log[feature][\"mean 1\"] = np.nanmean(rvs1)\n",
    "    stats_log[feature][\"mean 3\"] = np.nanmean(rvs3)\n",
    "    stats_log[feature][\"mean 12\"] = np.nanmean(rvs12)\n",
    "    \n",
    "    stats_log[feature][\"standard deviation 1\"] = np.nanstd(rvs1)\n",
    "    stats_log[feature][\"standard deviation 3\"] = np.nanstd(rvs3)\n",
    "    stats_log[feature][\"standard deviation 12\"] = np.nanstd(rvs12)\n",
    "    \n",
    "    stats_log[feature][\"p-value (1-3)\"] = stats.ttest_ind(rvs1, rvs3).pvalue\n",
    "    stats_log[feature][\"p-value (1-12)\"] = stats.ttest_ind(rvs1, rvs12).pvalue\n",
    "    stats_log[feature][\"p-value (3-12)\"] = stats.ttest_ind(rvs3, rvs12).pvalue\n",
    "\n",
    "\n",
    "stat_log_pd = pd.DataFrame(stats_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stat_log_pd.round(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test for significance for VA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "va_stats_logs = {}\n",
    "\n",
    "feature = \"cur_va_rounded\"\n",
    "abt_viz.cur_va_rounded_1.mean()\n",
    "\n",
    "rvs1 = abt_viz.loc[:, f\"{feature}_{1}\"]\n",
    "rvs3 = abt_viz.loc[:, f\"{feature}_{3}\"]\n",
    "rvs12 = abt_viz.loc[:, f\"{feature}_{12}\"]\n",
    "\n",
    "va_stats_logs[\"mean_1\"] = rvs1.mean()\n",
    "va_stats_logs[\"mean_3\"] = rvs3.mean()\n",
    "va_stats_logs[\"mean_12\"] = rvs12.mean()\n",
    "\n",
    "va_stats_logs[\"std_1\"] = rvs1.std()\n",
    "va_stats_logs[\"std_3\"] = rvs3.std()\n",
    "va_stats_logs[\"std_12\"] = rvs12.std()\n",
    "\n",
    "va_stats_logs[\"ptest_1-3\"] = stats.ttest_ind(rvs1, rvs3).pvalue\n",
    "va_stats_logs[\"ptest_1-12\"] = stats.ttest_ind(rvs1, rvs12).pvalue\n",
    "va_stats_logs[\"ptest_3-12\"] = stats.ttest_ind(rvs3, rvs12).pvalue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(va_stats_logs, index=[0]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filtered = data_pd[filter_1 & filter_3 & filter_12]\n",
    "\n",
    "dicoms = data_filtered[[\"study_date_1_dicom_path\", \"study_date_3_dicom_path\", \"study_date_12_dicom_path\"]]\n",
    "\n",
    "dicom_paths = pd.melt(dicoms)[\"value\"].tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tracking_library",
   "language": "python",
   "name": "tracking_library"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
