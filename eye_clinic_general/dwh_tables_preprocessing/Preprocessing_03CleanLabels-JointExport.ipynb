{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Clean Labels\n",
    "Clean each label file individually\n",
    "- Reads dwh tables from `/storage/groups/ml01/datasets/raw/2018_LMUAugenklinik_niklas.koehler/dwh_tables`\n",
    "- Writes cleaned dwh tables to `/storage/groups/ml01/datasets/projects/20181610_eyeclinic_niklas.koehler/dwh_tables_cleaned`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from ipywidgets import interact, fixed\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "from pydicom import read_file\n",
    "from tqdm import tqdm\n",
    "import imageio\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../DeepRT/thickness_map_calculation')\n",
    "import dicom_table as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DIR = \"/storage/groups/ml01/datasets/raw/2018_LMUAugenklinik_niklas.koehler\"\n",
    "DATA_DIR = \"/storage/groups/ml01/datasets/projects/20181610_eyeclinic_niklas.koehler\"\n",
    "\n",
    "raw_data_dir = os.path.join(RAW_DIR, 'joint_export/dwh_tables')\n",
    "clean_data_dir = os.path.join(DATA_DIR, 'joint_export/dwh_tables_cleaned')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean visus labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_logMAR(va):\n",
    "    # converts decimal va values to logMAR scale\n",
    "    try:\n",
    "        va = float(va)\n",
    "        if va == 0:\n",
    "            return np.inf\n",
    "        else:\n",
    "            return np.log10(1/va)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "def get_visual_acuity(group):\n",
    "    # parses items in ordered group. If first value cannot be parsed, moves on to next value\n",
    "    for i, raw in enumerate(list(group.visual_acuity_raw)):\n",
    "        va = parse_visual_acuity(raw)\n",
    "        if va is not None:\n",
    "            res = list(group.iloc[i])\n",
    "            res.append(va)\n",
    "            return res\n",
    "    return None\n",
    "\n",
    "def parse_visual_acuity(raw):\n",
    "    if pd.isna(raw):\n",
    "        return None\n",
    "    \n",
    "    # match range of two comma/dot separated values\n",
    "    m = re.match(r'.*(\\d+)[,\\.](\\d+)[ -]+(\\d+)[,\\.](\\d+).*$', raw)\n",
    "    if m:\n",
    "        return np.mean([float('{}.{}'.format(m.group(1), m.group(2))), \n",
    "                       float('{}.{}'.format(m.group(3), m.group(4)))])\n",
    "    \n",
    "    # match comma/dot separated value, allowing comma, space, \"sc\" as first character\n",
    "    m = re.match(r'[ ,\\.a-zA-Z]*([\\do]+)[\\., ]+(\\d+).*$', raw)\n",
    "    if m:\n",
    "        return float('{}.{}'.format(m.group(1).replace('o', '0'), m.group(2)))\n",
    "    \n",
    "    # match two integer values separated with /, allowing space, \"sc, HT\" as first character\n",
    "    m = re.match(r'[ a-zA-Z:]*(\\d+)[ /]+(\\d+)[a-zA-Z \\.]*$', raw)\n",
    "    if m:\n",
    "        return int(m.group(1))/float(m.group(2))\n",
    "        \n",
    "    # match HBW\n",
    "    if re.match(r'.*[hH]\\.*[bB]\\.*[wW]*\\.*', raw):\n",
    "        return 'HBW'\n",
    "    # match FZ\n",
    "    elif re.match(r'[fF]\\.*[zZ]\\.*', raw):\n",
    "        return 'FZ'\n",
    "    # match Lilo\n",
    "    elif re.match(r'li(cht){0,1}(lo(kal){0,1}){0,1}', raw, flags=re.IGNORECASE):\n",
    "        return 'LILO'\n",
    "    # match Nulla LUX\n",
    "    elif re.match(r'(n[ulla]*|kein)\\.* *l([ux\\.]*|[icht]*)', raw, flags=re.IGNORECASE):        \n",
    "        return 'NL'\n",
    "    # match FIX\n",
    "    elif re.match(r'fix.*', raw, flags=re.IGNORECASE):\n",
    "        return 'FIX'\n",
    "    # match LUX\n",
    "    elif re.match(r'.*lux.*', raw, flags=re.IGNORECASE):  \n",
    "        return 'LUX'\n",
    "    \n",
    "    else:\n",
    "        return \"other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icb/olle.holmberg/anaconda3/envs/tf2_super/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (5,8) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/home/icb/olle.holmberg/anaconda3/envs/tf2_super/lib/python3.6/site-packages/numpy/lib/arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with 1212908 measurements\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/icb/olle.holmberg/anaconda3/envs/tf2_super/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-5-db912836731b>\", line 23, in <module>\n",
      "    visus_labels.loc[visus_labels['laterality_raw'] == 'B', 'laterality'] = 'L'\n",
      "  File \"/home/icb/olle.holmberg/.local/lib/python3.6/site-packages/pandas/core/indexing.py\", line 670, in __setitem__\n",
      "    iloc._setitem_with_indexer(indexer, value)\n",
      "  File \"/home/icb/olle.holmberg/.local/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1542, in _setitem_with_indexer\n",
      "    take_split_path = self.obj._is_mixed_type\n",
      "  File \"/home/icb/olle.holmberg/.local/lib/python3.6/site-packages/pandas/core/generic.py\", line 5241, in _is_mixed_type\n",
      "    return self._protect_consolidate(f)\n",
      "  File \"/home/icb/olle.holmberg/.local/lib/python3.6/site-packages/pandas/core/generic.py\", line 5203, in _protect_consolidate\n",
      "    result = f()\n",
      "  File \"/home/icb/olle.holmberg/.local/lib/python3.6/site-packages/pandas/core/generic.py\", line 5240, in <lambda>\n",
      "    f = lambda: self._mgr.is_mixed_type\n",
      "  File \"/home/icb/olle.holmberg/.local/lib/python3.6/site-packages/pandas/core/internals/managers.py\", line 691, in is_mixed_type\n",
      "    self._consolidate_inplace()\n",
      "  File \"/home/icb/olle.holmberg/.local/lib/python3.6/site-packages/pandas/core/internals/managers.py\", line 979, in _consolidate_inplace\n",
      "    self.blocks = tuple(_consolidate(self.blocks))\n",
      "  File \"/home/icb/olle.holmberg/.local/lib/python3.6/site-packages/pandas/core/internals/managers.py\", line 1900, in _consolidate\n",
      "    list(group_blocks), dtype=dtype, can_consolidate=_can_consolidate\n",
      "  File \"/home/icb/olle.holmberg/.local/lib/python3.6/site-packages/pandas/core/internals/managers.py\", line 1926, in _merge_blocks\n",
      "    new_mgr_locs = new_mgr_locs[argsort]\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/icb/olle.holmberg/anaconda3/envs/tf2_super/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/icb/olle.holmberg/anaconda3/envs/tf2_super/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/icb/olle.holmberg/anaconda3/envs/tf2_super/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/icb/olle.holmberg/anaconda3/envs/tf2_super/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/icb/olle.holmberg/anaconda3/envs/tf2_super/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/icb/olle.holmberg/anaconda3/envs/tf2_super/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/icb/olle.holmberg/anaconda3/envs/tf2_super/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/icb/olle.holmberg/anaconda3/envs/tf2_super/lib/python3.6/inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/home/icb/olle.holmberg/anaconda3/envs/tf2_super/lib/python3.6/inspect.py\", line 709, in getabsfile\n",
      "    return os.path.normcase(os.path.abspath(_filename))\n",
      "  File \"/home/icb/olle.holmberg/anaconda3/envs/tf2_super/lib/python3.6/posixpath.py\", line 385, in abspath\n",
      "    return normpath(path)\n",
      "  File \"/home/icb/olle.holmberg/anaconda3/envs/tf2_super/lib/python3.6/posixpath.py\", line 359, in normpath\n",
      "    comps = path.split(sep)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-db912836731b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mvisus_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'laterality'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvisus_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'laterality_raw'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mvisus_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvisus_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'laterality_raw'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'B'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'laterality'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'L'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mvisus_R\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvisus_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvisus_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'laterality_raw'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'B'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlaterality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'R'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0miloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"iloc\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m         \u001b[0miloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m   1541\u001b[0m         \u001b[0;31m# maybe partial set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1542\u001b[0;31m         \u001b[0mtake_split_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_mixed_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_is_mixed_type\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5240\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_mixed_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5241\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_protect_consolidate\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m   5202\u001b[0m         \u001b[0mblocks_before\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5203\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mblocks_before\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5239\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_mixed_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool_t\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5240\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_mixed_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5241\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mis_mixed_type\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;31m# Warning, consolidation needs to get checked upstairs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_consolidated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_consolidate\u001b[0;34m(blocks)\u001b[0m\n\u001b[1;32m   1899\u001b[0m         merged_blocks = _merge_blocks(\n\u001b[0;32m-> 1900\u001b[0;31m             \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcan_consolidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_can_consolidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1901\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_merge_blocks\u001b[0;34m(blocks, dtype, can_consolidate)\u001b[0m\n\u001b[1;32m   1925\u001b[0m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1926\u001b[0;31m         \u001b[0mnew_mgr_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tf2_super/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2043\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2044\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2_super/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2046\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2047\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2049\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2_super/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1436\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2_super/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1334\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1336\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m             )\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2_super/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1193\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2_super/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2_super/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "visus_labels = pd.read_csv(os.path.join(raw_data_dir, 'visus_labels.csv'), index_col=0)\n",
    "print('Starting with {} measurements'.format(len(visus_labels)))\n",
    "\n",
    "# rename columns\n",
    "visus_labels.rename(columns={'AUGE': 'laterality_raw', 'MEASUREMENT_DATE':'study_date', 'PATNR':'patient_id',\n",
    "                            'visual_acuity_VISUS': 'visual_acuity_raw', 'ORIGIN_TYPE': 'visual_acuity_origin'}, \n",
    "                    inplace=True)\n",
    "\n",
    "# format columns \n",
    "visus_labels.study_date = pd.to_datetime(visus_labels.study_date)\n",
    "\n",
    "# imputer origin value, ok?\n",
    "visus_labels.visual_acuity_origin.fillna(\"OR\", inplace=True)\n",
    "\n",
    "visus_labels.visual_acuity_origin = pd.Categorical(visus_labels.visual_acuity_origin,\n",
    "                                                   ['SR', 'OR', 'CC', 'STP', 'SC'])\n",
    "\n",
    "# remove rows with missing study dates\n",
    "visus_labels = visus_labels[~ visus_labels.study_date.isna()]\n",
    "\n",
    "# duplicate entries for laterality=='B'\n",
    "visus_labels['laterality'] = visus_labels['laterality_raw']\n",
    "visus_labels.loc[visus_labels['laterality_raw'] == 'B', 'laterality'] = 'L'\n",
    "visus_R = visus_labels.loc[visus_labels['laterality_raw'] == 'B'].copy().assign(laterality='R')\n",
    "visus_labels = visus_labels.append(visus_R, ignore_index=True)\n",
    "\n",
    "# merge new values\n",
    "visus_labels.visual_acuity_raw.fillna(visus_labels.MEASUREMENT_VALUE, inplace=True)\n",
    "visus_labels.visual_acuity_raw.fillna(visus_labels.CALCULATED_VALUE, inplace=True)\n",
    "\n",
    "# convert integers strings to float strings\n",
    "visus_labels.loc[:, \"visual_acuity_raw\"] = visus_labels.visual_acuity_raw.replace({'1':'1.0'})\n",
    "visus_labels.loc[:, \"visual_acuity_raw\"] = visus_labels.visual_acuity_raw.replace({'0':'0.0'})\n",
    "\n",
    "# get rid of exact duplicates\n",
    "num_raw = visus_labels.shape[0]\n",
    "visus_labels = visus_labels.drop_duplicates(keep='first')\n",
    "num_raw_nodup = visus_labels.shape[0]\n",
    "print('Dropped {} exact duplicates'.format(num_raw-num_raw_nodup))\n",
    "\n",
    "# count duplicate measurements per time point\n",
    "num_dups = sum(visus_labels.duplicated(['study_date', 'patient_id', 'laterality']))\n",
    "print('Resolving {} duplicate measurements per time point'.format(num_dups))\n",
    "\n",
    "# group by time point measurements\n",
    "groups = visus_labels.groupby(['patient_id', 'laterality', 'study_date'])\n",
    "keys = groups.groups.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(visus_labels.CALCULATED_VALUE.isna()), sum(visus_labels.LOGMAR_VALUE.isna()), sum(visus_labels.MEASUREMENT_VALUE.isna()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save away all measurements to use for imputation later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_measurements = visus_labels[['patient_id', 'laterality', 'study_date', \n",
    "              \"CALCULATED_VALUE\", \"LOGMAR_VALUE\", \"MEASUREMENT_VALUE\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visus_labels.drop(columns=[\"CALCULATED_VALUE\", \"LOGMAR_VALUE\", \"MEASUREMENT_VALUE\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse all visual acuity values into rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Before visual acuity parsing: {} unique time/patient/laterality measurements'.format(len(keys)))\n",
    "\n",
    "rows = []\n",
    "for key in tqdm(keys):\n",
    "    # sort values to ensure that correct VA value is taken \n",
    "    grp = groups.get_group(key).sort_values('visual_acuity_origin')\n",
    "    res = get_visual_acuity(grp)\n",
    "    if res is not None:\n",
    "        rows.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visus_labels_clean = pd.DataFrame.from_records(rows, columns=['laterality_raw', 'study_date', \n",
    "                                                              'visual_acuity_origin',\n",
    "                                                              'patient_id', 'visual_acuity_raw', 'laterality', \n",
    "                                                              'visual_acuity'])\n",
    "\n",
    "print('Number of cleaned measurements {}'.format(visus_labels_clean.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add logMAR_raw column (unmapped, no string values)\n",
    "visus_labels_clean['logMAR_raw'] = visus_labels_clean.visual_acuity.apply(to_logMAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "va_num = visus_labels_clean['logMAR_raw']\n",
    "va_str = visus_labels_clean['visual_acuity_raw']\n",
    "\n",
    "# print frequency of logMAR values and strings\n",
    "nums, bins = np.histogram(va_num, bins=np.concatenate([[-np.inf], np.arange(-0.4,2.1,0.2), [10, np.inf]]))\n",
    "for i, num in enumerate(nums[:-1]):\n",
    "    print('[{:.1f},{:.1f}):\\t{}'.format(bins[i], bins[i+1], nums[i]))\n",
    "print('[{:.1f},{:.1f}]:\\t{}'.format(bins[-2], bins[-1], nums[-1]))\n",
    "\n",
    "for s in ['FZ', 'HBW', 'FIX', 'LILO', 'LUX', 'NL']:\n",
    "    print('{}:\\t\\t{}'.format(s, sum(va_str==s)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "map logMAR and string values: (using values from https://michaelbach.de/sci/acuity.html)\n",
    "- logMAR < -0.3 gets mapped to -0.3\n",
    "- logMAR == inf gets mapped to value for NL (va 0 means blind!)\n",
    "- OLD: logMAR > 2.0 gets mapped to 2.0. This is not done anymore, values stay as is!\n",
    "- FZ (count fingers) gets mapped to 1.9\n",
    "- HBW gets mapped to 2.3 \n",
    "- FIX/LILO gets mapped to 2.6\n",
    "- LUX gets mapped to 2.8\n",
    "- NL gets mapped to 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visus_labels_clean['logMAR'] = visus_labels_clean.logMAR_raw\n",
    "# mapping logMAR values\n",
    "visus_labels_clean.loc[visus_labels_clean.logMAR_raw<-0.3, 'logMAR'] = -0.3\n",
    "#visus_labels_clean.loc[visus_labels_clean.logMAR_raw>2.0, 'logMAR'] = 2.0\n",
    "visus_labels_clean.loc[visus_labels_clean.logMAR_raw==np.inf, 'logMAR'] = 3.0\n",
    "# string values\n",
    "visus_labels_clean.loc[visus_labels_clean.visual_acuity=='FZ', 'logMAR'] = 1.9\n",
    "visus_labels_clean.loc[visus_labels_clean.visual_acuity=='HBW', 'logMAR'] = 2.3\n",
    "visus_labels_clean.loc[visus_labels_clean.visual_acuity=='FIX', 'logMAR'] = 2.6\n",
    "visus_labels_clean.loc[visus_labels_clean.visual_acuity=='LILO', 'logMAR'] = 2.6\n",
    "visus_labels_clean.loc[visus_labels_clean.visual_acuity=='LUX', 'logMAR'] = 2.8\n",
    "visus_labels_clean.loc[visus_labels_clean.visual_acuity=='NL', 'logMAR'] = 3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match other measurements to potential CALCULATED Values\n",
    "\n",
    "As only na values were replaced by \"CALCULATED_VALUE\" or \"LOGMAR_VALUE\" or \"MEASUREMENT_VALUE\". \n",
    "\n",
    "Some none na values were not successfully parsed and transformed to logMAR, thus the below code\n",
    "replaces those we precomputed logMAR provided from the last export.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_meas_columns = [\"study_date\", \"patient_id\", \"laterality\", \"LOGMAR_VALUE\"]\n",
    "visus_labels_clean_ = pd.merge(visus_labels_clean, all_measurements[all_meas_columns].drop_duplicates(), \n",
    "                                 on=[\"study_date\", \"patient_id\", \"laterality\"], how=\"left\").drop_duplicates()\n",
    "\n",
    "visus_labels_clean_.loc[:, \"logMAR\"] = visus_labels_clean_.logMAR.fillna(visus_labels_clean_.LOGMAR_VALUE)\n",
    "\n",
    "visus_labels_clean_ = visus_labels_clean_[~visus_labels_clean_.logMAR.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Integrate supplement table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load supplement table\n",
    "manual_va_check = pd.read_excel(os.path.join(raw_data_dir, \"supplement_tables/visual_ac_check.xlsx\"), \n",
    "                                engine='openpyxl')\n",
    "\n",
    "# filter for cases with first va and first OCT less than 2 months apart\n",
    "delta = manual_va_check.first_oct_date_registrered_wo_visual_acuity - manual_va_check.date_va_first_injection\n",
    "\n",
    "manual_va_check = manual_va_check[np.abs(delta).dt.days < 60]\n",
    "\n",
    "# load supplement table\n",
    "manual_va_check = pd.read_excel(os.path.join(raw_data_dir, \"supplement_tables/visual_ac_check.xlsx\"), \n",
    "                                engine='openpyxl')\n",
    "\n",
    "\n",
    "# format into visus table clean format\n",
    "manual_va_check_f = manual_va_check[[\"patient_id\", \"laterality\", \"first_oct_date_registrered_wo_visual_acuity\", \"va_first_injection\"]]\n",
    "manual_va_check_f = manual_va_check_f.dropna()\n",
    "\n",
    "manual_va_check_f.loc[:, \"laterality_raw\"] = manual_va_check_f.laterality\n",
    "manual_va_check_f.loc[:, \"visual_acuity_origin\"] = \"nan\"\n",
    "\n",
    "manual_va_check_f = manual_va_check_f.rename(columns={\"first_oct_date_registrered_wo_visual_acuity\": \"study_date\", \n",
    "                                                      \"va_first_injection\": \"visual_acuity_raw\"})\n",
    "\n",
    "manual_va_check_f.loc[:, \"visual_acuity\"] = manual_va_check_f.visual_acuity_raw\n",
    "manual_va_check_f.loc[:, \"laterality_raw\"] = manual_va_check_f.laterality\n",
    "\n",
    "# add logMAR_raw column (unmapped, no string values)\n",
    "manual_va_check_f.loc[:, 'logMAR_raw'] = manual_va_check_f.visual_acuity.apply(to_logMAR)\n",
    "manual_va_check_f.loc[:, \"logMAR\"] = manual_va_check_f.logMAR_raw\n",
    "\n",
    "manual_va_check_f.loc[:, \"patient_id\"] = manual_va_check_f.patient_id.astype(int)\n",
    "\n",
    "\n",
    "# append to main table\n",
    "#visus_labels_clean_ = visus_labels_clean_.drop([\"LOGMAR_VALUE\"], axis=1)\n",
    "visus_labels_clean_ = pd.concat([visus_labels_clean_, manual_va_check_f])\n",
    "\n",
    "# drop duplicates\n",
    "visus_labels_clean_ = visus_labels_clean_.drop_duplicates(subset=[\"patient_id\", \"laterality\", \"study_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print frequency of logMAR values and strings\n",
    "nums, bins = np.histogram(visus_labels_clean_.logMAR, bins=np.concatenate([[-np.inf], np.arange(-0.401,3.1,0.2), [np.inf]]))\n",
    "for i, num in enumerate(nums[:-1]):\n",
    "    print('[{:.3f},{:.3f}):\\t{}'.format(bins[i], bins[i+1], nums[i]))\n",
    "print('[{:.3f},{:.3f}]:\\t{}'.format(bins[-2], bins[-1], nums[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cleaned table\n",
    "visus_labels_clean_.to_csv(os.path.join(clean_data_dir, 'visus_labels_clean.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis = pd.read_csv(os.path.join(raw_data_dir, 'diagnosis.csv'), index_col=0)\n",
    "print('Starting with {} measurements'.format(len(diagnosis)))\n",
    "\n",
    "# rename columns\n",
    "diagnosis.rename(columns={'LOK': 'laterality_raw', 'DAT':'study_date', 'PATNR':'patient_id', 'DKAT':'DKAT', 'DKEY':'diagnosis'}, inplace=True)\n",
    "\n",
    "# format columns \n",
    "diagnosis.study_date = pd.to_datetime(diagnosis.study_date)\n",
    "diagnosis.diagnosis = diagnosis.diagnosis.astype('str')\n",
    "\n",
    "# remove non-eye related diagnoses\n",
    "diagnosis['category'] = diagnosis.diagnosis.apply(lambda x: x[0])\n",
    "diagnosis = diagnosis[diagnosis.category == 'H']  # TODO need to include 'E' as well for diabetic retinopathy\n",
    "print('Starting with {} diagnoses of eye diseases'.format(len(diagnosis)))\n",
    "\n",
    "\n",
    "# duplicate entries for laterality=='B'\n",
    "diagnosis['laterality'] = diagnosis['laterality_raw']\n",
    "diagnosis.loc[diagnosis['laterality_raw'] == 'B', 'laterality'] = 'L'\n",
    "diagnosis_R = diagnosis.loc[diagnosis['laterality_raw'] == 'B'].copy().assign(laterality='R')\n",
    "diagnosis = diagnosis.append(diagnosis_R, ignore_index=True)\n",
    "\n",
    "# removing duplicates\n",
    "diagnosis = diagnosis.drop_duplicates()\n",
    "print('After removing duplicates: {} diagnoses'.format(len(diagnosis)))\n",
    "\n",
    "diagnosis = diagnosis.dropna(subset=[\"laterality\"])\n",
    "# todo drop nan laterality diagnoses? \n",
    "# put duplicate diagnoses in list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load descriptions of diagnoses\n",
    "diagnosis_code = pd.read_csv(os.path.join(clean_data_dir, 'icd10cm_order_2018.txt'), sep='\\t', header=None)\n",
    "\n",
    "codes = []\n",
    "desc = []\n",
    "for i in range(len(diagnosis_code)):\n",
    "    code = diagnosis_code[0][i]\n",
    "    codes.append(code[6:14].strip())\n",
    "    desc.append(code[16:77].strip())\n",
    "    \n",
    "diagnosis_code['diagnosis'] = codes\n",
    "diagnosis_code['description'] = desc\n",
    "diagnosis_code = diagnosis_code[['diagnosis', 'description']]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistics\n",
    "diag = list(diagnosis['diagnosis'])\n",
    "diag_cl = []\n",
    "for d in diag:\n",
    "    if len(re.findall(r'H\\d\\d\\.\\d', d)) > 0:\n",
    "        diag_cl.append(d)\n",
    "        \n",
    "unique, counts = np.unique(diag_cl, return_counts=True)\n",
    "\n",
    "# sort by frequency\n",
    "unique_sorted = [x for _,x in sorted(zip(counts,unique), reverse=True)]\n",
    "counts_sorted = sorted(counts, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    desc = diagnosis_code[diagnosis_code.diagnosis==unique_sorted[i].replace('.','')].description\n",
    "    try:\n",
    "        desc = desc.iloc[0]\n",
    "    except IndexError:\n",
    "        desc = ''\n",
    "    print('{}: {}: {}'.format(counts_sorted[i], unique_sorted[i], desc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(counts_sorted)), [int(u) for u in counts_sorted])\n",
    "plt.xlim(0,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cleaned table\n",
    "diagnosis.to_csv(os.path.join(clean_data_dir, 'diagnosis_clean.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procedures = pd.read_csv(os.path.join(raw_data_dir, 'prozeduren.csv'), index_col=0)\n",
    "\n",
    "# rename columns\n",
    "procedures.rename(columns={'LOK': 'laterality_raw', 'DAT':'study_date', 'PATNR':'patient_id'}, inplace=True)\n",
    "# format columns \n",
    "procedures.study_date = pd.to_datetime(procedures.study_date)\n",
    "\n",
    "# duplicate entries for laterality=='B'\n",
    "procedures['laterality_raw'].fillna('B', inplace=True)\n",
    "procedures['laterality'] = procedures['laterality_raw']\n",
    "procedures.loc[procedures['laterality_raw'] == 'B', 'laterality'] = 'L'\n",
    "procedures_R = procedures.loc[procedures['laterality_raw'] == 'B'].copy().assign(laterality='R')\n",
    "procedures = procedures.append(procedures_R, ignore_index=True)\n",
    "\n",
    "# get rid of exact duplicates\n",
    "num_raw = procedures.shape[0]\n",
    "procedures = procedures.drop_duplicates(keep='first')\n",
    "num_raw_nodup = procedures.shape[0]\n",
    "print('Dropped {} exact duplicates'.format(num_raw-num_raw_nodup))\n",
    "\n",
    "# take care of duplicate measurements per time point\n",
    "num_dups = sum(procedures.duplicated(['study_date', 'patient_id', 'laterality']))\n",
    "print('Resolving {} duplicate measurements per time point'.format(num_dups))\n",
    "\n",
    "# remove everything not in chapter 5 08-16 (surgeries of the eye)\n",
    "procedures_filtered = procedures[procedures.ICPML.apply(lambda x: x[:4] in ['5-08','5-09','5-10','5-11','5-12','5-13','5-14','5-15','5-16'])]\n",
    "# reduce code to 3 decimals\n",
    "procedures_filtered.ICPML = procedures_filtered.loc[:,'ICPML'].apply(lambda x: x[:5])\n",
    "print('Number of filtered procedures {}'.format(len(procedures_filtered)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list most common procedures\n",
    "unique, counts = np.unique(list(procedures_filtered.ICPML), return_counts=True)\n",
    "unqiue = [u for _,u in sorted(zip(counts, unique), reverse=True)]\n",
    "counts = sorted(counts, reverse=True)\n",
    "\n",
    "for i in range(20):\n",
    "    print(unqiue[i], counts[i])\n",
    "    \n",
    "plt.plot(range(len(counts)), [int(u) for u in counts])\n",
    "plt.xlim(0,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "codes with highest occurrence:\n",
    "- 5-984 nicht relevant\n",
    "- 5-156.9 - Injektionen\n",
    "- 5-154 - Netzhautfixierung\n",
    "- 5-144 - Extrakapsul√§re Extraktion der Linse\n",
    "- 5-158 - Vitrektomie\n",
    "- 5-985 - Lasertechnik, nicht relevant\n",
    "- 5-159 - Vitrektomie\n",
    "- 5-155 - Destruktion von erkranktem Gewebe an Retina und Choroidea\n",
    "- 5-010 - nicht relevant\n",
    "- 5-091 - Exzision und Destruktion von (erkranktem) Gewebe des Augenlides, nicht relevant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save procedures - not quite clean\n",
    "procedures_filtered.to_csv(os.path.join(clean_data_dir, 'procedures_clean.csv'))\n",
    "print('Saved {} procedures'.format(len(procedures_filtered)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'procedures_filtered' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0526e567a84e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprocedures_filtered\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'procedures_filtered' is not defined"
     ]
    }
   ],
   "source": [
    "procedures_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get OCT and fundus maps\n",
    "### OCTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of oct paths before dropping duplicates:  326657\n",
      "Number of oct paths after dropping duplicates:  212091\n"
     ]
    }
   ],
   "source": [
    "oct_meta_information = pd.read_csv(os.path.join(RAW_DIR,\"joint_export\", 'oct_meta_information.csv'))\n",
    "\n",
    "columns_oi = [\"PATNR\", \"laterality\", \"study_date\", \"oct_path\"]\n",
    "octs = oct_meta_information[columns_oi]\n",
    "\n",
    "# rename columns\n",
    "octs = octs.rename(columns={\"PATNR\":\"patient_id\"})\n",
    "\n",
    "# add non existing fundus path\n",
    "octs[\"fundus_path\"] = None\n",
    "\n",
    "print(\"Number of oct paths before dropping duplicates: \", octs.shape[0])\n",
    "\n",
    "# drop any duplicates\n",
    "octs_no_dups = octs.drop_duplicates(subset=[\"patient_id\", \"laterality\", \"study_date\"])\n",
    "\n",
    "print(\"Number of oct paths after dropping duplicates: \", octs_no_dups.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cleaned table\n",
    "octs.to_csv(os.path.join(clean_data_dir, 'octs_fundus_with_dups.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### duplicate OCTs\n",
    "- some are unreadable, or have the wrong format\n",
    "- of the duplicates, often one will be of the optical nerve and the other of the macula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have 114566 duplicated octs\n"
     ]
    }
   ],
   "source": [
    "octs_nona = octs.dropna(subset=['patient_id', 'laterality', 'study_date'])\n",
    "\n",
    "idx_cols = ['patient_id', 'laterality', 'study_date']\n",
    "print('Have {} duplicated octs'.format(sum(octs_nona.duplicated(idx_cols))))\n",
    "\n",
    "dup_octs = octs_nona[octs_nona.duplicated(idx_cols, keep=False)]\n",
    "octs_grouped = dup_octs.groupby(idx_cols)\n",
    "oct_keys = octs_grouped.groups.keys()\n",
    "\n",
    "octs_nona = octs_nona.sort_values(\"study_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have 118861 non-duplicated octs\n"
     ]
    }
   ],
   "source": [
    "nodup_octs = octs_nona.drop_duplicates(idx_cols, keep=False)\n",
    "print('Have {} non-duplicated octs'.format(len(nodup_octs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deal with duplicate octs\n",
    "... by throwing them out\n",
    "- in the future, might need to come back to this and do sth more advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cleaned table\n",
    "octs_no_dups.to_csv(os.path.join(clean_data_dir, 'octs_fundus_no_dups.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2_super",
   "language": "python",
   "name": "tf2_super"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
